{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "605d387d-ceb7-48fd-8fea-dd4b731a46ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 16:31:37.257644: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-23 16:31:37.431950: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-02-23 16:31:38.238877: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-02-23 16:31:38.239055: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-02-23 16:31:38.239070: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from keras.utils import plot_model\n",
    "from scipy.spatial import distance\n",
    "from scipy.spatial.distance import cdist, cosine\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboard.plugins import projector\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28ea2ea4-7828-4dfa-9ed7-b7116c9bf041",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['season', 'overall', 'potential', \n",
    "           #'age', 'height_cm', 'weight_kg', 'league_level', \n",
    "           'height_cm', 'weight_kg',\n",
    "           'skill_moves', #'international_reputation', \n",
    "           'pace', 'shooting', 'passing', 'dribbling', 'defending', 'physic', \n",
    "           'attacking_crossing', 'attacking_finishing', 'attacking_heading_accuracy', 'attacking_short_passing', 'attacking_volleys', \n",
    "           'skill_dribbling', 'skill_curve', 'skill_fk_accuracy', 'skill_long_passing', 'skill_ball_control', \n",
    "           'movement_acceleration', 'movement_sprint_speed', 'movement_agility', 'movement_reactions', 'movement_balance', \n",
    "           'power_shot_power', 'power_jumping', 'power_stamina', 'power_strength', 'power_long_shots', \n",
    "           'mentality_aggression', 'mentality_interceptions', 'mentality_positioning', 'mentality_vision', 'mentality_penalties', 'mentality_composure', \n",
    "           'defending_marking_awareness', 'defending_standing_tackle', 'defending_sliding_tackle', \n",
    "           'ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf', 'rw', \n",
    "           'lam', 'cam', 'ram', 'lm', 'lcm', 'cm', 'rcm', 'rm', \n",
    "           'lwb', 'ldm', 'cdm', 'rdm', 'rwb', 'lb', 'lcb', 'cb', 'rcb', 'rb', \n",
    "           #### Traits\n",
    "           'One Club Player', 'Avoids Using Weaker Foot', 'Playmaker', 'Dives Into Tackles', 'Finesse Shot', \n",
    "           'Power Free-Kick', 'Leadership', 'Power Header', 'Technical Dribbler', 'Early Crosser', 'Takes Finesse Free Kicks', \n",
    "           'Through Ball', 'Giant Throw-in', 'Beat Offside Trap', 'Outside Foot Shot', 'Long Passer', 'Set Play Specialist', 'Chip Shot', \n",
    "           'Diver', 'Team Player', 'Injury Free', 'Injury Prone', 'Swerve Pass', 'Solid Player', 'Selfish', 'Speed Dribbler', 'Flair', \n",
    "           'Long Shot Taker', 'Long Throw-in', 'Backs Into Player', 'Target Forward', \n",
    "           #### Tags (Remove)\n",
    "           #'Speedster', 'Complete Defender', 'Dribbler', \n",
    "           #'Tackling', 'Acrobat', 'Poacher', 'Crosser', 'FK Specialist', 'Complete Forward', 'Complete Midfielder', 'Engine', \n",
    "           #'Clinical Finisher', 'Aerial Threat', 'Tactician', 'Distance Shooter', 'Strength', \n",
    "           \n",
    "           #### Newly created\n",
    "           'att_workrate', 'def_workrate', 'body_Lean', 'body_Normal', 'body_Stocky', 'body_Unique', 'right_foot', 'left_foot', \n",
    "           'injury_risk', 'teamwork', 'passing_traits', 'attacking_traits', 'dribbling_traits', 'defending_traits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c47f7ff-735e-4449-af0a-344b1d15b0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>overall</th>\n",
       "      <th>potential</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>skill_moves</th>\n",
       "      <th>pace</th>\n",
       "      <th>shooting</th>\n",
       "      <th>passing</th>\n",
       "      <th>dribbling</th>\n",
       "      <th>...</th>\n",
       "      <th>body_Stocky</th>\n",
       "      <th>body_Unique</th>\n",
       "      <th>right_foot</th>\n",
       "      <th>left_foot</th>\n",
       "      <th>injury_risk</th>\n",
       "      <th>teamwork</th>\n",
       "      <th>passing_traits</th>\n",
       "      <th>attacking_traits</th>\n",
       "      <th>dribbling_traits</th>\n",
       "      <th>defending_traits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1415</td>\n",
       "      <td>93</td>\n",
       "      <td>95</td>\n",
       "      <td>169</td>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "      <td>93.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1415</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>185</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>93.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1415</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>93.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1415</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>195</td>\n",
       "      <td>95</td>\n",
       "      <td>4</td>\n",
       "      <td>76.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1415</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>170</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>75.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126283</th>\n",
       "      <td>2122</td>\n",
       "      <td>47</td>\n",
       "      <td>52</td>\n",
       "      <td>180</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126284</th>\n",
       "      <td>2122</td>\n",
       "      <td>47</td>\n",
       "      <td>59</td>\n",
       "      <td>175</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>59.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126285</th>\n",
       "      <td>2122</td>\n",
       "      <td>47</td>\n",
       "      <td>55</td>\n",
       "      <td>178</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>60.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126286</th>\n",
       "      <td>2122</td>\n",
       "      <td>47</td>\n",
       "      <td>60</td>\n",
       "      <td>173</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>68.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126287</th>\n",
       "      <td>2122</td>\n",
       "      <td>47</td>\n",
       "      <td>60</td>\n",
       "      <td>167</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>68.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126288 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        season  overall  potential  height_cm  weight_kg  skill_moves  pace  \\\n",
       "0         1415       93         95        169         67            4  93.0   \n",
       "1         1415       92         92        185         80            5  93.0   \n",
       "2         1415       90         90        180         80            4  93.0   \n",
       "3         1415       90         90        195         95            4  76.0   \n",
       "4         1415       89         89        170         65            4  75.0   \n",
       "...        ...      ...        ...        ...        ...          ...   ...   \n",
       "126283    2122       47         52        180         64            2  58.0   \n",
       "126284    2122       47         59        175         70            2  59.0   \n",
       "126285    2122       47         55        178         72            2  60.0   \n",
       "126286    2122       47         60        173         66            2  68.0   \n",
       "126287    2122       47         60        167         61            2  68.0   \n",
       "\n",
       "        shooting  passing  dribbling  ...  body_Stocky  body_Unique  \\\n",
       "0           89.0     86.0       96.0  ...            0            0   \n",
       "1           93.0     81.0       91.0  ...            0            0   \n",
       "2           86.0     83.0       92.0  ...            0            0   \n",
       "3           91.0     81.0       86.0  ...            0            0   \n",
       "4           72.0     89.0       91.0  ...            0            0   \n",
       "...          ...      ...        ...  ...          ...          ...   \n",
       "126283      35.0     46.0       48.0  ...            0            0   \n",
       "126284      39.0     50.0       46.0  ...            0            0   \n",
       "126285      37.0     45.0       49.0  ...            0            0   \n",
       "126286      46.0     36.0       48.0  ...            0            0   \n",
       "126287      38.0     45.0       48.0  ...            0            0   \n",
       "\n",
       "        right_foot  left_foot  injury_risk  teamwork  passing_traits  \\\n",
       "0                3          5            0         1               0   \n",
       "1                5          4            0         0               0   \n",
       "2                2          5            1        -1               0   \n",
       "3                5          4            0         1               0   \n",
       "4                5          4            0         0               1   \n",
       "...            ...        ...          ...       ...             ...   \n",
       "126283           5          3            0         0               0   \n",
       "126284           5          3            0         0               0   \n",
       "126285           5          3            0         0               0   \n",
       "126286           5          3            0         0               0   \n",
       "126287           5          3            0         0               0   \n",
       "\n",
       "        attacking_traits  dribbling_traits  defending_traits  \n",
       "0                      1                 1                 0  \n",
       "1                      1                 1                 0  \n",
       "2                      2                 1                 0  \n",
       "3                      1                 1                 0  \n",
       "4                      1                 1                 0  \n",
       "...                  ...               ...               ...  \n",
       "126283                 0                 0                 0  \n",
       "126284                 0                 0                 0  \n",
       "126285                 0                 0                 0  \n",
       "126286                 0                 0                 0  \n",
       "126287                 0                 0                 0  \n",
       "\n",
       "[126288 rows x 112 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('final_data/fifa_cleaned_all_columns.csv').drop(['Unnamed: 0'], axis=1)[columns]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64198427-d1ea-4a76-87bc-64b1eeaf1d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1415, 1516, 1617, 1718, 1819, 1920, 2021, 2122])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.season.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fd55fe1-c9c9-4150-a813-a409addbc40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>overall</th>\n",
       "      <th>potential</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>skill_moves</th>\n",
       "      <th>pace</th>\n",
       "      <th>shooting</th>\n",
       "      <th>passing</th>\n",
       "      <th>dribbling</th>\n",
       "      <th>...</th>\n",
       "      <th>body_Stocky</th>\n",
       "      <th>body_Unique</th>\n",
       "      <th>right_foot</th>\n",
       "      <th>left_foot</th>\n",
       "      <th>injury_risk</th>\n",
       "      <th>teamwork</th>\n",
       "      <th>passing_traits</th>\n",
       "      <th>attacking_traits</th>\n",
       "      <th>dribbling_traits</th>\n",
       "      <th>defending_traits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1415</td>\n",
       "      <td>93</td>\n",
       "      <td>95</td>\n",
       "      <td>169</td>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "      <td>93.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1415</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>185</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>93.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1415</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>93.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1415</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>195</td>\n",
       "      <td>95</td>\n",
       "      <td>4</td>\n",
       "      <td>76.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1415</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>170</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>75.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28299</th>\n",
       "      <td>1516</td>\n",
       "      <td>44</td>\n",
       "      <td>59</td>\n",
       "      <td>168</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>57.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28300</th>\n",
       "      <td>1516</td>\n",
       "      <td>44</td>\n",
       "      <td>60</td>\n",
       "      <td>180</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>65.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28301</th>\n",
       "      <td>1516</td>\n",
       "      <td>44</td>\n",
       "      <td>60</td>\n",
       "      <td>178</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>64.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28302</th>\n",
       "      <td>1516</td>\n",
       "      <td>44</td>\n",
       "      <td>59</td>\n",
       "      <td>180</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>67.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28303</th>\n",
       "      <td>1516</td>\n",
       "      <td>44</td>\n",
       "      <td>56</td>\n",
       "      <td>173</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>69.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28304 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       season  overall  potential  height_cm  weight_kg  skill_moves  pace  \\\n",
       "0        1415       93         95        169         67            4  93.0   \n",
       "1        1415       92         92        185         80            5  93.0   \n",
       "2        1415       90         90        180         80            4  93.0   \n",
       "3        1415       90         90        195         95            4  76.0   \n",
       "4        1415       89         89        170         65            4  75.0   \n",
       "...       ...      ...        ...        ...        ...          ...   ...   \n",
       "28299    1516       44         59        168         54            2  57.0   \n",
       "28300    1516       44         60        180         72            2  65.0   \n",
       "28301    1516       44         60        178         66            2  64.0   \n",
       "28302    1516       44         59        180         69            2  67.0   \n",
       "28303    1516       44         56        173         69            2  69.0   \n",
       "\n",
       "       shooting  passing  dribbling  ...  body_Stocky  body_Unique  \\\n",
       "0          89.0     86.0       96.0  ...            0            0   \n",
       "1          93.0     81.0       91.0  ...            0            0   \n",
       "2          86.0     83.0       92.0  ...            0            0   \n",
       "3          91.0     81.0       86.0  ...            0            0   \n",
       "4          72.0     89.0       91.0  ...            0            0   \n",
       "...         ...      ...        ...  ...          ...          ...   \n",
       "28299      35.0     42.0       50.0  ...            0            0   \n",
       "28300      22.0     33.0       37.0  ...            0            0   \n",
       "28301      32.0     49.0       48.0  ...            0            0   \n",
       "28302      41.0     45.0       50.0  ...            0            0   \n",
       "28303      34.0     44.0       49.0  ...            0            0   \n",
       "\n",
       "       right_foot  left_foot  injury_risk  teamwork  passing_traits  \\\n",
       "0               3          5            0         1               0   \n",
       "1               5          4            0         0               0   \n",
       "2               2          5            1        -1               0   \n",
       "3               5          4            0         1               0   \n",
       "4               5          4            0         0               1   \n",
       "...           ...        ...          ...       ...             ...   \n",
       "28299           5          2            0         0               0   \n",
       "28300           5          2            0         0               0   \n",
       "28301           5          3            0         0               0   \n",
       "28302           5          3            0         0               0   \n",
       "28303           5          3            0         0               0   \n",
       "\n",
       "       attacking_traits  dribbling_traits  defending_traits  \n",
       "0                     1                 1                 0  \n",
       "1                     1                 1                 0  \n",
       "2                     2                 1                 0  \n",
       "3                     1                 1                 0  \n",
       "4                     1                 1                 0  \n",
       "...                 ...               ...               ...  \n",
       "28299                 0                 0                 0  \n",
       "28300                 0                 0                 0  \n",
       "28301                 0                 0                 0  \n",
       "28302                 0                 0                 0  \n",
       "28303                 0                 0                 0  \n",
       "\n",
       "[28304 rows x 112 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['season'] <=1516]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e86f4a30-9f80-4385-8f29-114f23423c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ae_train(season, emb_dim = 20, epochs=50, batch_size=32):\n",
    "    ### Train test Split\n",
    "    X = df[df['season'] <=season].copy()\n",
    "    # Target\n",
    "    y = df[df['season'] <=season]['overall']\n",
    "\n",
    "    # Train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15, random_state=42)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    input = tf.keras.layers.Input(shape=X_train.shape[1:])\n",
    "\n",
    "    encoder = tf.keras.layers.Dense(X_train.shape[1:][0], activation='relu')(input)\n",
    "    encoder = tf.keras.layers.Dense(100, activation='relu')(encoder)\n",
    "    encoder = tf.keras.layers.Dense(75, activation='relu')(encoder)\n",
    "    encoder = tf.keras.layers.Dense(50, activation='relu')(encoder)\n",
    "    embedding = tf.keras.layers.Dense(emb_dim, activation='relu',name='embedding')(encoder)\n",
    "\n",
    "    decoder = tf.keras.layers.Dense(50, activation='relu')(embedding)\n",
    "    decoder = tf.keras.layers.Dense(75, activation='relu')(decoder)\n",
    "    decoder = tf.keras.layers.Dense(100, activation='relu')(decoder)\n",
    "    decoder = tf.keras.layers.Dense(X_train.shape[1], activation='sigmoid')(decoder),\n",
    "\n",
    "    autoencoder = Model(input, decoder)\n",
    "    autoencoder.compile(loss='mae', optimizer='adam')\n",
    "    callback = EarlyStopping(monitor='loss', patience=3)\n",
    "    history = autoencoder.fit(X_train, X_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, #shuffle=False, \n",
    "                callbacks=[callback], validation_data = (X_test, X_test))\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79381374-834e-43e1-a68a-d88d55c2aaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training # of sample: 14380\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 16:31:41.407102: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-23 16:31:41.417092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-23 16:31:41.418955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-23 16:31:41.421088: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-23 16:31:41.422190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-23 16:31:41.423951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-23 16:31:41.425712: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-23 16:31:42.113732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-23 16:31:42.115564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-23 16:31:42.117039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-23 16:31:42.118493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 344 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "382/382 [==============================] - 3s 4ms/step - loss: 0.0849 - val_loss: 0.0554\n",
      "Epoch 2/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0531 - val_loss: 0.0510\n",
      "Epoch 3/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0495 - val_loss: 0.0481\n",
      "Epoch 4/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0471 - val_loss: 0.0461\n",
      "Epoch 5/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0460 - val_loss: 0.0459\n",
      "Epoch 6/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0453 - val_loss: 0.0454\n",
      "Epoch 7/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0449 - val_loss: 0.0449\n",
      "Epoch 8/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0442 - val_loss: 0.0437\n",
      "Epoch 9/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0436 - val_loss: 0.0432\n",
      "Epoch 10/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0429 - val_loss: 0.0426\n",
      "Epoch 11/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0423 - val_loss: 0.0424\n",
      "Epoch 12/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0419 - val_loss: 0.0427\n",
      "Epoch 13/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0414 - val_loss: 0.0413\n",
      "Epoch 14/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.0414 - val_loss: 0.0424\n",
      "Epoch 15/50\n",
      "382/382 [==============================] - 1s 4ms/step - loss: 0.0412 - val_loss: 0.0412\n",
      "Epoch 16/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0411 - val_loss: 0.0413\n",
      "Epoch 17/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0412 - val_loss: 0.0417\n",
      "Epoch 18/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0409 - val_loss: 0.0410\n",
      "Epoch 19/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0408 - val_loss: 0.0410\n",
      "Epoch 20/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0408 - val_loss: 0.0419\n",
      "Epoch 21/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0408 - val_loss: 0.0409\n",
      "Epoch 22/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0407 - val_loss: 0.0404\n",
      "Epoch 23/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0403 - val_loss: 0.0418\n",
      "Epoch 24/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0403 - val_loss: 0.0403\n",
      "Epoch 25/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0400 - val_loss: 0.0403\n",
      "Epoch 26/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0399 - val_loss: 0.0398\n",
      "Epoch 27/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0396 - val_loss: 0.0401\n",
      "Epoch 28/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0395 - val_loss: 0.0395\n",
      "Epoch 29/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0394 - val_loss: 0.0392\n",
      "Epoch 30/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0391 - val_loss: 0.0394\n",
      "Epoch 31/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0389 - val_loss: 0.0394\n",
      "Epoch 32/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0388 - val_loss: 0.0394\n",
      "Epoch 33/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0387 - val_loss: 0.0391\n",
      "Epoch 34/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0386 - val_loss: 0.0389\n",
      "Epoch 35/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0386 - val_loss: 0.0396\n",
      "Epoch 36/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0385 - val_loss: 0.0389\n",
      "Epoch 37/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0385 - val_loss: 0.0385\n",
      "Epoch 38/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0384 - val_loss: 0.0385\n",
      "Epoch 39/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0384 - val_loss: 0.0385\n",
      "Epoch 40/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0383 - val_loss: 0.0385\n",
      "Epoch 41/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0385 - val_loss: 0.0383\n",
      "Epoch 42/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0383 - val_loss: 0.0387\n",
      "Epoch 43/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0382 - val_loss: 0.0387\n",
      "Epoch 44/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0383 - val_loss: 0.0386\n",
      "Epoch 45/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0383 - val_loss: 0.0385\n",
      "Epoch 46/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0382 - val_loss: 0.0385\n",
      "Epoch 47/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0382 - val_loss: 0.0384\n",
      "Epoch 48/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0382 - val_loss: 0.0384\n",
      "Epoch 49/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0382 - val_loss: 0.0383\n",
      "Epoch 50/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0380 - val_loss: 0.0386\n",
      "Completed Training # of sample: 14380\n",
      "\n",
      "\n",
      "Start Training # of sample: 28304\n",
      "\n",
      "Epoch 1/50\n",
      "752/752 [==============================] - 3s 3ms/step - loss: 0.0711 - val_loss: 0.0565\n",
      "Epoch 2/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0533 - val_loss: 0.0510\n",
      "Epoch 3/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0499 - val_loss: 0.0485\n",
      "Epoch 4/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0484 - val_loss: 0.0456\n",
      "Epoch 5/50\n",
      "752/752 [==============================] - 3s 4ms/step - loss: 0.0446 - val_loss: 0.0442\n",
      "Epoch 6/50\n",
      "752/752 [==============================] - 3s 3ms/step - loss: 0.0435 - val_loss: 0.0431\n",
      "Epoch 7/50\n",
      "752/752 [==============================] - 3s 3ms/step - loss: 0.0428 - val_loss: 0.0424\n",
      "Epoch 8/50\n",
      "752/752 [==============================] - 3s 3ms/step - loss: 0.0424 - val_loss: 0.0419\n",
      "Epoch 9/50\n",
      "752/752 [==============================] - 3s 3ms/step - loss: 0.0423 - val_loss: 0.0418\n",
      "Epoch 10/50\n",
      "752/752 [==============================] - 3s 3ms/step - loss: 0.0414 - val_loss: 0.0406\n",
      "Epoch 11/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0406 - val_loss: 0.0407\n",
      "Epoch 12/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0403 - val_loss: 0.0399\n",
      "Epoch 13/50\n",
      "752/752 [==============================] - 3s 3ms/step - loss: 0.0402 - val_loss: 0.0403\n",
      "Epoch 14/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0397 - val_loss: 0.0390\n",
      "Epoch 15/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0386 - val_loss: 0.0373\n",
      "Epoch 16/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0375 - val_loss: 0.0375\n",
      "Epoch 17/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0372 - val_loss: 0.0369\n",
      "Epoch 18/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0370 - val_loss: 0.0366\n",
      "Epoch 19/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0370 - val_loss: 0.0371\n",
      "Epoch 20/50\n",
      "752/752 [==============================] - 3s 3ms/step - loss: 0.0368 - val_loss: 0.0369\n",
      "Epoch 21/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0357 - val_loss: 0.0349\n",
      "Epoch 22/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0352 - val_loss: 0.0349\n",
      "Epoch 23/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0352 - val_loss: 0.0350\n",
      "Epoch 24/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0351 - val_loss: 0.0352\n",
      "Epoch 25/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0349 - val_loss: 0.0348\n",
      "Epoch 26/50\n",
      "752/752 [==============================] - 3s 3ms/step - loss: 0.0348 - val_loss: 0.0347\n",
      "Epoch 27/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0347 - val_loss: 0.0345\n",
      "Epoch 28/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0345 - val_loss: 0.0346\n",
      "Epoch 29/50\n",
      "752/752 [==============================] - 3s 4ms/step - loss: 0.0343 - val_loss: 0.0346\n",
      "Epoch 30/50\n",
      "752/752 [==============================] - 3s 3ms/step - loss: 0.0342 - val_loss: 0.0339\n",
      "Epoch 31/50\n",
      "752/752 [==============================] - 3s 3ms/step - loss: 0.0341 - val_loss: 0.0340\n",
      "Epoch 32/50\n",
      "752/752 [==============================] - 3s 3ms/step - loss: 0.0338 - val_loss: 0.0339\n",
      "Epoch 33/50\n",
      "752/752 [==============================] - 3s 3ms/step - loss: 0.0335 - val_loss: 0.0339\n",
      "Epoch 34/50\n",
      "752/752 [==============================] - 3s 3ms/step - loss: 0.0335 - val_loss: 0.0332\n",
      "Epoch 35/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0335 - val_loss: 0.0335\n",
      "Epoch 36/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0334 - val_loss: 0.0335\n",
      "Epoch 37/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0335 - val_loss: 0.0335\n",
      "Epoch 38/50\n",
      "752/752 [==============================] - 3s 3ms/step - loss: 0.0333 - val_loss: 0.0340\n",
      "Epoch 39/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0333 - val_loss: 0.0333\n",
      "Epoch 40/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0332 - val_loss: 0.0334\n",
      "Epoch 41/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0332 - val_loss: 0.0337\n",
      "Epoch 42/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0330 - val_loss: 0.0328\n",
      "Epoch 43/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0329 - val_loss: 0.0327\n",
      "Epoch 44/50\n",
      "752/752 [==============================] - 3s 3ms/step - loss: 0.0327 - val_loss: 0.0327\n",
      "Epoch 45/50\n",
      "752/752 [==============================] - 3s 3ms/step - loss: 0.0326 - val_loss: 0.0324\n",
      "Epoch 46/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0326 - val_loss: 0.0326\n",
      "Epoch 47/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0325 - val_loss: 0.0324\n",
      "Epoch 48/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0326 - val_loss: 0.0323\n",
      "Epoch 49/50\n",
      "752/752 [==============================] - 2s 3ms/step - loss: 0.0324 - val_loss: 0.0323\n",
      "Epoch 50/50\n",
      "752/752 [==============================] - 3s 3ms/step - loss: 0.0324 - val_loss: 0.0321\n",
      "Completed Training # of sample: 28304\n",
      "\n",
      "\n",
      "Start Training # of sample: 43907\n",
      "\n",
      "Epoch 1/50\n",
      "1167/1167 [==============================] - 5s 3ms/step - loss: 0.0686 - val_loss: 0.0525\n",
      "Epoch 2/50\n",
      "1167/1167 [==============================] - 4s 4ms/step - loss: 0.0509 - val_loss: 0.0490\n",
      "Epoch 3/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0480 - val_loss: 0.0468\n",
      "Epoch 4/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0466 - val_loss: 0.0458\n",
      "Epoch 5/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0449 - val_loss: 0.0433\n",
      "Epoch 6/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0401 - val_loss: 0.0390\n",
      "Epoch 7/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0391 - val_loss: 0.0385\n",
      "Epoch 8/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0388 - val_loss: 0.0384\n",
      "Epoch 9/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0384 - val_loss: 0.0382\n",
      "Epoch 10/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0375 - val_loss: 0.0367\n",
      "Epoch 11/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0368 - val_loss: 0.0380\n",
      "Epoch 12/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0365 - val_loss: 0.0368\n",
      "Epoch 13/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0363 - val_loss: 0.0360\n",
      "Epoch 14/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0360 - val_loss: 0.0360\n",
      "Epoch 15/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 16/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 17/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 18/50\n",
      "1167/1167 [==============================] - 4s 4ms/step - loss: 0.0356 - val_loss: 0.0352\n",
      "Epoch 19/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0356 - val_loss: 0.0355\n",
      "Epoch 20/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0353 - val_loss: 0.0351\n",
      "Epoch 21/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0348 - val_loss: 0.0345\n",
      "Epoch 22/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0347 - val_loss: 0.0346\n",
      "Epoch 23/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0345 - val_loss: 0.0341\n",
      "Epoch 24/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0345 - val_loss: 0.0342\n",
      "Epoch 25/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0344 - val_loss: 0.0342\n",
      "Epoch 26/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0345 - val_loss: 0.0342\n",
      "Epoch 27/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0343 - val_loss: 0.0345\n",
      "Epoch 28/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0343 - val_loss: 0.0338\n",
      "Epoch 29/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0343 - val_loss: 0.0341\n",
      "Epoch 30/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0343 - val_loss: 0.0339\n",
      "Epoch 31/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0343 - val_loss: 0.0341\n",
      "Epoch 32/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0343 - val_loss: 0.0339\n",
      "Epoch 33/50\n",
      "1167/1167 [==============================] - 4s 4ms/step - loss: 0.0342 - val_loss: 0.0342\n",
      "Epoch 34/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0342 - val_loss: 0.0346\n",
      "Epoch 35/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0342 - val_loss: 0.0343\n",
      "Epoch 36/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0342 - val_loss: 0.0338\n",
      "Epoch 37/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0341 - val_loss: 0.0338\n",
      "Epoch 38/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0341 - val_loss: 0.0341\n",
      "Epoch 39/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0340 - val_loss: 0.0338\n",
      "Epoch 40/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0340 - val_loss: 0.0342\n",
      "Epoch 41/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0339 - val_loss: 0.0336\n",
      "Epoch 42/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0339 - val_loss: 0.0336\n",
      "Epoch 43/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0339 - val_loss: 0.0336\n",
      "Epoch 44/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0338 - val_loss: 0.0338\n",
      "Epoch 45/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0338 - val_loss: 0.0335\n",
      "Epoch 46/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0337 - val_loss: 0.0335\n",
      "Epoch 47/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0333 - val_loss: 0.0331\n",
      "Epoch 48/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0331 - val_loss: 0.0327\n",
      "Epoch 49/50\n",
      "1167/1167 [==============================] - 4s 4ms/step - loss: 0.0331 - val_loss: 0.0331\n",
      "Epoch 50/50\n",
      "1167/1167 [==============================] - 4s 3ms/step - loss: 0.0330 - val_loss: 0.0340\n",
      "Completed Training # of sample: 43907\n",
      "\n",
      "\n",
      "Start Training # of sample: 59842\n",
      "\n",
      "Epoch 1/50\n",
      "1590/1590 [==============================] - 6s 3ms/step - loss: 0.0613 - val_loss: 0.0503\n",
      "Epoch 2/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0491 - val_loss: 0.0478\n",
      "Epoch 3/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0474 - val_loss: 0.0451\n",
      "Epoch 4/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0446 - val_loss: 0.0436\n",
      "Epoch 5/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0433 - val_loss: 0.0426\n",
      "Epoch 6/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0423 - val_loss: 0.0415\n",
      "Epoch 7/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0415 - val_loss: 0.0407\n",
      "Epoch 8/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0409 - val_loss: 0.0413\n",
      "Epoch 9/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0404 - val_loss: 0.0401\n",
      "Epoch 10/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0402 - val_loss: 0.0401\n",
      "Epoch 11/50\n",
      "1590/1590 [==============================] - 6s 4ms/step - loss: 0.0399 - val_loss: 0.0399\n",
      "Epoch 12/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0394 - val_loss: 0.0401\n",
      "Epoch 13/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0390 - val_loss: 0.0391\n",
      "Epoch 14/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0388 - val_loss: 0.0387\n",
      "Epoch 15/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0387 - val_loss: 0.0382\n",
      "Epoch 16/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0385 - val_loss: 0.0384\n",
      "Epoch 17/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0383 - val_loss: 0.0384\n",
      "Epoch 18/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0381 - val_loss: 0.0380\n",
      "Epoch 19/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0380 - val_loss: 0.0378\n",
      "Epoch 20/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0379 - val_loss: 0.0385\n",
      "Epoch 21/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0377 - val_loss: 0.0375\n",
      "Epoch 22/50\n",
      "1590/1590 [==============================] - 6s 4ms/step - loss: 0.0376 - val_loss: 0.0374\n",
      "Epoch 23/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0375 - val_loss: 0.0385\n",
      "Epoch 24/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0374 - val_loss: 0.0367\n",
      "Epoch 25/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0374 - val_loss: 0.0369\n",
      "Epoch 26/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0373 - val_loss: 0.0368\n",
      "Epoch 27/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0372 - val_loss: 0.0368\n",
      "Epoch 28/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0372 - val_loss: 0.0369\n",
      "Epoch 29/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0372 - val_loss: 0.0368\n",
      "Epoch 30/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0371 - val_loss: 0.0364\n",
      "Epoch 31/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0370 - val_loss: 0.0367\n",
      "Epoch 32/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0370 - val_loss: 0.0366\n",
      "Epoch 33/50\n",
      "1590/1590 [==============================] - 6s 4ms/step - loss: 0.0369 - val_loss: 0.0363\n",
      "Epoch 34/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0366 - val_loss: 0.0362\n",
      "Epoch 35/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0352 - val_loss: 0.0340\n",
      "Epoch 36/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0341 - val_loss: 0.0340\n",
      "Epoch 37/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0339 - val_loss: 0.0335\n",
      "Epoch 38/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0311 - val_loss: 0.0310\n",
      "Epoch 39/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0307 - val_loss: 0.0299\n",
      "Epoch 40/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0305 - val_loss: 0.0305\n",
      "Epoch 41/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0305 - val_loss: 0.0307\n",
      "Epoch 42/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0304 - val_loss: 0.0299\n",
      "Epoch 43/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0304 - val_loss: 0.0304\n",
      "Epoch 44/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0303 - val_loss: 0.0299\n",
      "Epoch 45/50\n",
      "1590/1590 [==============================] - 6s 4ms/step - loss: 0.0303 - val_loss: 0.0295\n",
      "Epoch 46/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0302 - val_loss: 0.0297\n",
      "Epoch 47/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0302 - val_loss: 0.0298\n",
      "Epoch 48/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0302 - val_loss: 0.0299\n",
      "Epoch 49/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0302 - val_loss: 0.0302\n",
      "Epoch 50/50\n",
      "1590/1590 [==============================] - 5s 3ms/step - loss: 0.0301 - val_loss: 0.0298\n",
      "Completed Training # of sample: 59842\n",
      "\n",
      "\n",
      "Start Training # of sample: 75898\n",
      "\n",
      "Epoch 1/50\n",
      "2017/2017 [==============================] - 7s 3ms/step - loss: 0.0600 - val_loss: 0.0514\n",
      "Epoch 2/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0484 - val_loss: 0.0545\n",
      "Epoch 3/50\n",
      "2017/2017 [==============================] - 7s 3ms/step - loss: 0.0471 - val_loss: 0.0476\n",
      "Epoch 4/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0453 - val_loss: 0.0458\n",
      "Epoch 5/50\n",
      "2017/2017 [==============================] - 7s 3ms/step - loss: 0.0441 - val_loss: 0.0442\n",
      "Epoch 6/50\n",
      "2017/2017 [==============================] - 7s 3ms/step - loss: 0.0422 - val_loss: 0.0433\n",
      "Epoch 7/50\n",
      "2017/2017 [==============================] - 7s 3ms/step - loss: 0.0415 - val_loss: 0.0430\n",
      "Epoch 8/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0413 - val_loss: 0.0431\n",
      "Epoch 9/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0411 - val_loss: 0.0419\n",
      "Epoch 10/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0375 - val_loss: 0.0348\n",
      "Epoch 11/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0342 - val_loss: 0.0345\n",
      "Epoch 12/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0339 - val_loss: 0.0343\n",
      "Epoch 13/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0334 - val_loss: 0.0334\n",
      "Epoch 14/50\n",
      "2017/2017 [==============================] - 7s 4ms/step - loss: 0.0329 - val_loss: 0.0347\n",
      "Epoch 15/50\n",
      "2017/2017 [==============================] - 7s 3ms/step - loss: 0.0321 - val_loss: 0.0333\n",
      "Epoch 16/50\n",
      "2017/2017 [==============================] - 7s 3ms/step - loss: 0.0318 - val_loss: 0.0338\n",
      "Epoch 17/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0317 - val_loss: 0.0341\n",
      "Epoch 18/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0317 - val_loss: 0.0350\n",
      "Epoch 19/50\n",
      "2017/2017 [==============================] - 7s 3ms/step - loss: 0.0317 - val_loss: 0.0327\n",
      "Epoch 20/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0316 - val_loss: 0.0326\n",
      "Epoch 21/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0315 - val_loss: 0.0323\n",
      "Epoch 22/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0313 - val_loss: 0.0320\n",
      "Epoch 23/50\n",
      "2017/2017 [==============================] - 7s 3ms/step - loss: 0.0311 - val_loss: 0.0330\n",
      "Epoch 24/50\n",
      "2017/2017 [==============================] - 7s 3ms/step - loss: 0.0309 - val_loss: 0.0319\n",
      "Epoch 25/50\n",
      "2017/2017 [==============================] - 7s 3ms/step - loss: 0.0308 - val_loss: 0.0320\n",
      "Epoch 26/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0308 - val_loss: 0.0313\n",
      "Epoch 27/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0307 - val_loss: 0.0317\n",
      "Epoch 28/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0306 - val_loss: 0.0321\n",
      "Epoch 29/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0306 - val_loss: 0.0317\n",
      "Epoch 30/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0306 - val_loss: 0.0319\n",
      "Epoch 31/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0306 - val_loss: 0.0316\n",
      "Epoch 32/50\n",
      "2017/2017 [==============================] - 7s 3ms/step - loss: 0.0305 - val_loss: 0.0319\n",
      "Epoch 33/50\n",
      "2017/2017 [==============================] - 7s 3ms/step - loss: 0.0305 - val_loss: 0.0320\n",
      "Epoch 34/50\n",
      "2017/2017 [==============================] - 7s 3ms/step - loss: 0.0304 - val_loss: 0.0314\n",
      "Epoch 35/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0304 - val_loss: 0.0321\n",
      "Epoch 36/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0304 - val_loss: 0.0307\n",
      "Epoch 37/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0303 - val_loss: 0.0308\n",
      "Epoch 38/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0304 - val_loss: 0.0310\n",
      "Epoch 39/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0303 - val_loss: 0.0338\n",
      "Epoch 40/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0303 - val_loss: 0.0312\n",
      "Epoch 41/50\n",
      "2017/2017 [==============================] - 7s 3ms/step - loss: 0.0303 - val_loss: 0.0330\n",
      "Epoch 42/50\n",
      "2017/2017 [==============================] - 7s 3ms/step - loss: 0.0303 - val_loss: 0.0318\n",
      "Epoch 43/50\n",
      "2017/2017 [==============================] - 7s 3ms/step - loss: 0.0303 - val_loss: 0.0306\n",
      "Epoch 44/50\n",
      "2017/2017 [==============================] - 7s 3ms/step - loss: 0.0303 - val_loss: 0.0316\n",
      "Epoch 45/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0302 - val_loss: 0.0326\n",
      "Epoch 46/50\n",
      "2017/2017 [==============================] - 7s 3ms/step - loss: 0.0303 - val_loss: 0.0336\n",
      "Epoch 47/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0303 - val_loss: 0.0323\n",
      "Epoch 48/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0302 - val_loss: 0.0310\n",
      "Epoch 49/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0302 - val_loss: 0.0305\n",
      "Epoch 50/50\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 0.0302 - val_loss: 0.0322\n",
      "Completed Training # of sample: 75898\n",
      "\n",
      "\n",
      "Start Training # of sample: 92320\n",
      "\n",
      "Epoch 1/50\n",
      "2453/2453 [==============================] - 9s 3ms/step - loss: 0.0573 - val_loss: 0.0495\n",
      "Epoch 2/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0466 - val_loss: 0.0444\n",
      "Epoch 3/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0437 - val_loss: 0.0436\n",
      "Epoch 4/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0425 - val_loss: 0.0420\n",
      "Epoch 5/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0414 - val_loss: 0.0416\n",
      "Epoch 6/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0406 - val_loss: 0.0403\n",
      "Epoch 7/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0403 - val_loss: 0.0400\n",
      "Epoch 8/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0396 - val_loss: 0.0391\n",
      "Epoch 9/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0388 - val_loss: 0.0385\n",
      "Epoch 10/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0386 - val_loss: 0.0385\n",
      "Epoch 11/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0385 - val_loss: 0.0381\n",
      "Epoch 12/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0384 - val_loss: 0.0397\n",
      "Epoch 13/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0379 - val_loss: 0.0376\n",
      "Epoch 14/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0377 - val_loss: 0.0380\n",
      "Epoch 15/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0376 - val_loss: 0.0374\n",
      "Epoch 16/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0375 - val_loss: 0.0381\n",
      "Epoch 17/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0375 - val_loss: 0.0372\n",
      "Epoch 18/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0375 - val_loss: 0.0372\n",
      "Epoch 19/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0374 - val_loss: 0.0373\n",
      "Epoch 20/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0374 - val_loss: 0.0376\n",
      "Epoch 21/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0374 - val_loss: 0.0371\n",
      "Epoch 22/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0374 - val_loss: 0.0373\n",
      "Epoch 23/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0373 - val_loss: 0.0374\n",
      "Epoch 24/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0373 - val_loss: 0.0376\n",
      "Epoch 25/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0372 - val_loss: 0.0379\n",
      "Epoch 26/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0372 - val_loss: 0.0374\n",
      "Epoch 27/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0372 - val_loss: 0.0375\n",
      "Epoch 28/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0372 - val_loss: 0.0367\n",
      "Epoch 29/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0372 - val_loss: 0.0368\n",
      "Epoch 30/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0371 - val_loss: 0.0372\n",
      "Epoch 31/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0371 - val_loss: 0.0370\n",
      "Epoch 32/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0371 - val_loss: 0.0369\n",
      "Epoch 33/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0371 - val_loss: 0.0367\n",
      "Epoch 34/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0371 - val_loss: 0.0371\n",
      "Epoch 35/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0370 - val_loss: 0.0375\n",
      "Epoch 36/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0370 - val_loss: 0.0372\n",
      "Epoch 37/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0370 - val_loss: 0.0370\n",
      "Epoch 38/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0370 - val_loss: 0.0369\n",
      "Epoch 39/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0369 - val_loss: 0.0368\n",
      "Epoch 40/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0369 - val_loss: 0.0368\n",
      "Epoch 41/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0369 - val_loss: 0.0369\n",
      "Epoch 42/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0369 - val_loss: 0.0369\n",
      "Epoch 43/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0368 - val_loss: 0.0365\n",
      "Epoch 44/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0367 - val_loss: 0.0374\n",
      "Epoch 45/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0367 - val_loss: 0.0365\n",
      "Epoch 46/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0366 - val_loss: 0.0369\n",
      "Epoch 47/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0366 - val_loss: 0.0364\n",
      "Epoch 48/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0364 - val_loss: 0.0372\n",
      "Epoch 49/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0361 - val_loss: 0.0357\n",
      "Epoch 50/50\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 0.0359 - val_loss: 0.0356\n",
      "Completed Training # of sample: 92320\n",
      "\n",
      "\n",
      "Start Training # of sample: 109181\n",
      "\n",
      "Epoch 1/50\n",
      "2890/2901 [============================>.] - ETA: 0s - loss: 0.0546"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for season in df.season.unique():\n",
    "    print('Start Training # of sample: ' + str(len(df[df['season'] <=season])) + '\\n')\n",
    "    results.append(ae_train(season))\n",
    "    print('Completed Training # of sample: ' + str(len(df[df['season'] <=season])) + '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2f09e9-c98c-4bbe-9fe1-06f081002c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac589c3e-6d1d-413c-9b44-37c9ee83c817",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For Players Autoencoder Hyperparameter Tuning: ')\n",
    "print('MAE of Dimension 10: ' + str(min(results[0].history['val_loss'])))\n",
    "print('MAE of Dimension 15: ' + str(min(results[1].history['val_loss'])))\n",
    "print('MAE of Dimension 20: ' + str(min(results[2].history['val_loss'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2 (Local)",
   "language": "python",
   "name": "local-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
