{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf17ef98-d1df-4370-88a3-800b2317654b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 16:23:13.883831: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-21 16:23:16.432255: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-02-21 16:23:20.545630: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-02-21 16:23:20.545896: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-02-21 16:23:20.545912: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.spatial import distance\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from keras.utils import plot_model\n",
    "from scipy.spatial.distance import cdist, cosine\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboard.plugins import projector\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff056caf-6b1c-4e1b-9f25-f25d66abcd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_embedding = pd.read_csv('player_embedding.csv').drop(['Unnamed: 0'], axis=1).iloc[:,3:]\n",
    "df = pd.read_csv('final_data/fifa_cleaned_all_columns.csv').drop(['Unnamed: 0'], axis=1)\n",
    "player_details = df[['club_name','short_name','overall','season']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e869aa39-ecf1-40e5-94a6-e0167f798882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          CF\n",
       "1          LW\n",
       "2          RM\n",
       "3          ST\n",
       "4          CM\n",
       "         ... \n",
       "126283    CDM\n",
       "126284     CM\n",
       "126285     CM\n",
       "126286     ST\n",
       "126287    CAM\n",
       "Length: 126288, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_position(club_pos):\n",
    "    pos = club_pos.split(\",\")[0]\n",
    "    return pos\n",
    "position = df.apply(lambda x: get_position(x['player_positions']), axis=1)\n",
    "position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462b34aa-1181-4d06-ab7b-71e60059890d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.265667</td>\n",
       "      <td>0.757148</td>\n",
       "      <td>1.709361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.870791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.932092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.050203</td>\n",
       "      <td>0.779398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.547777</td>\n",
       "      <td>2.535839</td>\n",
       "      <td>0.914676</td>\n",
       "      <td>1.284182</td>\n",
       "      <td>1.337910</td>\n",
       "      <td>1.294660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.758625</td>\n",
       "      <td>1.209742</td>\n",
       "      <td>1.564240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.474581</td>\n",
       "      <td>0.460083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.521481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.467055</td>\n",
       "      <td>0.986364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.773616</td>\n",
       "      <td>2.456737</td>\n",
       "      <td>0.486339</td>\n",
       "      <td>0.508786</td>\n",
       "      <td>0.510534</td>\n",
       "      <td>1.164134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.898894</td>\n",
       "      <td>1.266350</td>\n",
       "      <td>1.875545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.957869</td>\n",
       "      <td>0.040286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.886252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.966359</td>\n",
       "      <td>0.767043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.300267</td>\n",
       "      <td>2.276494</td>\n",
       "      <td>1.297398</td>\n",
       "      <td>0.690070</td>\n",
       "      <td>0.657781</td>\n",
       "      <td>1.098054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.622704</td>\n",
       "      <td>1.384349</td>\n",
       "      <td>1.968731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.689646</td>\n",
       "      <td>0.611457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.577605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.934327</td>\n",
       "      <td>0.825177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.274490</td>\n",
       "      <td>1.901708</td>\n",
       "      <td>0.385015</td>\n",
       "      <td>1.425968</td>\n",
       "      <td>0.401931</td>\n",
       "      <td>0.913824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.284001</td>\n",
       "      <td>1.387072</td>\n",
       "      <td>2.395956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.186806</td>\n",
       "      <td>0.054275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.419867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.816368</td>\n",
       "      <td>1.042094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.159883</td>\n",
       "      <td>2.955362</td>\n",
       "      <td>0.189032</td>\n",
       "      <td>0.535729</td>\n",
       "      <td>0.991364</td>\n",
       "      <td>1.050213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126283</th>\n",
       "      <td>0.463187</td>\n",
       "      <td>0.528406</td>\n",
       "      <td>0.896661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989502</td>\n",
       "      <td>1.371228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.669588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600177</td>\n",
       "      <td>0.927473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705462</td>\n",
       "      <td>1.019581</td>\n",
       "      <td>0.764323</td>\n",
       "      <td>0.865071</td>\n",
       "      <td>0.617943</td>\n",
       "      <td>0.469705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126284</th>\n",
       "      <td>0.459426</td>\n",
       "      <td>0.739470</td>\n",
       "      <td>0.860212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998605</td>\n",
       "      <td>1.291639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.672569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.471460</td>\n",
       "      <td>0.524431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.756158</td>\n",
       "      <td>1.039984</td>\n",
       "      <td>0.670674</td>\n",
       "      <td>0.754113</td>\n",
       "      <td>0.496114</td>\n",
       "      <td>0.379089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126285</th>\n",
       "      <td>0.583554</td>\n",
       "      <td>0.534359</td>\n",
       "      <td>0.883899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.025931</td>\n",
       "      <td>1.386753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.701014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.592992</td>\n",
       "      <td>0.746789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.712209</td>\n",
       "      <td>0.987118</td>\n",
       "      <td>0.721504</td>\n",
       "      <td>1.002327</td>\n",
       "      <td>0.550613</td>\n",
       "      <td>0.527887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126286</th>\n",
       "      <td>0.524298</td>\n",
       "      <td>0.523198</td>\n",
       "      <td>0.106561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.139934</td>\n",
       "      <td>1.555437</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.601059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.505016</td>\n",
       "      <td>0.555318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.317611</td>\n",
       "      <td>0.408143</td>\n",
       "      <td>0.491084</td>\n",
       "      <td>1.087960</td>\n",
       "      <td>0.779156</td>\n",
       "      <td>0.582550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126287</th>\n",
       "      <td>0.477626</td>\n",
       "      <td>0.485325</td>\n",
       "      <td>0.789953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.968748</td>\n",
       "      <td>1.572309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.646985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408577</td>\n",
       "      <td>0.723735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.097772</td>\n",
       "      <td>1.140498</td>\n",
       "      <td>0.626529</td>\n",
       "      <td>1.020352</td>\n",
       "      <td>0.640790</td>\n",
       "      <td>0.605206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126288 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0        3.265667   0.757148   1.709361        0.0   1.870791   0.000000   \n",
       "1        3.758625   1.209742   1.564240        0.0   0.474581   0.460083   \n",
       "2        2.898894   1.266350   1.875545        0.0   1.957869   0.040286   \n",
       "3        3.622704   1.384349   1.968731        0.0   0.689646   0.611457   \n",
       "4        2.284001   1.387072   2.395956        0.0   1.186806   0.054275   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "126283   0.463187   0.528406   0.896661        0.0   0.989502   1.371228   \n",
       "126284   0.459426   0.739470   0.860212        0.0   0.998605   1.291639   \n",
       "126285   0.583554   0.534359   0.883899        0.0   1.025931   1.386753   \n",
       "126286   0.524298   0.523198   0.106561        0.0   1.139934   1.555437   \n",
       "126287   0.477626   0.485325   0.789953        0.0   0.968748   1.572309   \n",
       "\n",
       "        feature_6  feature_7  feature_8  feature_9  feature_10  feature_11  \\\n",
       "0             0.0        0.0   0.932092        0.0    1.050203    0.779398   \n",
       "1             0.0        0.0   0.521481        0.0    1.467055    0.986364   \n",
       "2             0.0        0.0   0.886252        0.0    0.966359    0.767043   \n",
       "3             0.0        0.0   0.577605        0.0    0.934327    0.825177   \n",
       "4             0.0        0.0   1.419867        0.0    0.816368    1.042094   \n",
       "...           ...        ...        ...        ...         ...         ...   \n",
       "126283        0.0        0.0   0.669588        0.0    0.600177    0.927473   \n",
       "126284        0.0        0.0   0.672569        0.0    0.471460    0.524431   \n",
       "126285        0.0        0.0   0.701014        0.0    0.592992    0.746789   \n",
       "126286        0.0        0.0   0.601059        0.0    0.505016    0.555318   \n",
       "126287        0.0        0.0   0.646985        0.0    0.408577    0.723735   \n",
       "\n",
       "        feature_12  feature_13  feature_14  feature_15  feature_16  \\\n",
       "0              0.0         0.0    3.547777    2.535839    0.914676   \n",
       "1              0.0         0.0    2.773616    2.456737    0.486339   \n",
       "2              0.0         0.0    3.300267    2.276494    1.297398   \n",
       "3              0.0         0.0    2.274490    1.901708    0.385015   \n",
       "4              0.0         0.0    2.159883    2.955362    0.189032   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "126283         0.0         0.0    0.705462    1.019581    0.764323   \n",
       "126284         0.0         0.0    0.756158    1.039984    0.670674   \n",
       "126285         0.0         0.0    0.712209    0.987118    0.721504   \n",
       "126286         0.0         0.0    1.317611    0.408143    0.491084   \n",
       "126287         0.0         0.0    1.097772    1.140498    0.626529   \n",
       "\n",
       "        feature_17  feature_18  feature_19  \n",
       "0         1.284182    1.337910    1.294660  \n",
       "1         0.508786    0.510534    1.164134  \n",
       "2         0.690070    0.657781    1.098054  \n",
       "3         1.425968    0.401931    0.913824  \n",
       "4         0.535729    0.991364    1.050213  \n",
       "...            ...         ...         ...  \n",
       "126283    0.865071    0.617943    0.469705  \n",
       "126284    0.754113    0.496114    0.379089  \n",
       "126285    1.002327    0.550613    0.527887  \n",
       "126286    1.087960    0.779156    0.582550  \n",
       "126287    1.020352    0.640790    0.605206  \n",
       "\n",
       "[126288 rows x 20 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b31a201-0ba2-4815-8f28-2ee8c2839053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>club_name</th>\n",
       "      <th>short_name</th>\n",
       "      <th>overall</th>\n",
       "      <th>season</th>\n",
       "      <th>best_pos</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>key</th>\n",
       "      <th>defender</th>\n",
       "      <th>player_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43907</th>\n",
       "      <td>Real Madrid CF</td>\n",
       "      <td>Cristiano Ronaldo</td>\n",
       "      <td>94</td>\n",
       "      <td>1718</td>\n",
       "      <td>LW</td>\n",
       "      <td>4.122661</td>\n",
       "      <td>1.222620</td>\n",
       "      <td>1.456111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.423369</td>\n",
       "      <td>2.852642</td>\n",
       "      <td>0.299847</td>\n",
       "      <td>0.576179</td>\n",
       "      <td>0.748574</td>\n",
       "      <td>1.174775</td>\n",
       "      <td>Real Madrid CF1718</td>\n",
       "      <td>ND</td>\n",
       "      <td>Real Madrid CF1718ND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59842</th>\n",
       "      <td>Juventus</td>\n",
       "      <td>Cristiano Ronaldo</td>\n",
       "      <td>94</td>\n",
       "      <td>1819</td>\n",
       "      <td>ST</td>\n",
       "      <td>4.006461</td>\n",
       "      <td>1.190789</td>\n",
       "      <td>1.405771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.936381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.313507</td>\n",
       "      <td>2.750958</td>\n",
       "      <td>0.377921</td>\n",
       "      <td>0.566794</td>\n",
       "      <td>0.707652</td>\n",
       "      <td>1.149878</td>\n",
       "      <td>Juventus1819</td>\n",
       "      <td>ND</td>\n",
       "      <td>Juventus1819ND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59843</th>\n",
       "      <td>FC Barcelona</td>\n",
       "      <td>L. Messi</td>\n",
       "      <td>94</td>\n",
       "      <td>1819</td>\n",
       "      <td>CF</td>\n",
       "      <td>3.385196</td>\n",
       "      <td>0.747430</td>\n",
       "      <td>2.103769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.436939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.431670</td>\n",
       "      <td>2.777207</td>\n",
       "      <td>0.796833</td>\n",
       "      <td>1.467861</td>\n",
       "      <td>1.355075</td>\n",
       "      <td>1.453514</td>\n",
       "      <td>FC Barcelona1819</td>\n",
       "      <td>ND</td>\n",
       "      <td>FC Barcelona1819ND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14380</th>\n",
       "      <td>FC Barcelona</td>\n",
       "      <td>L. Messi</td>\n",
       "      <td>94</td>\n",
       "      <td>1516</td>\n",
       "      <td>RW</td>\n",
       "      <td>3.246406</td>\n",
       "      <td>0.807521</td>\n",
       "      <td>1.621410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.192120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.447260</td>\n",
       "      <td>2.568624</td>\n",
       "      <td>0.887763</td>\n",
       "      <td>1.365363</td>\n",
       "      <td>1.271545</td>\n",
       "      <td>1.224468</td>\n",
       "      <td>FC Barcelona1516</td>\n",
       "      <td>ND</td>\n",
       "      <td>FC Barcelona1516ND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28304</th>\n",
       "      <td>Real Madrid CF</td>\n",
       "      <td>Cristiano Ronaldo</td>\n",
       "      <td>94</td>\n",
       "      <td>1617</td>\n",
       "      <td>LW</td>\n",
       "      <td>4.126410</td>\n",
       "      <td>1.259415</td>\n",
       "      <td>1.360926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.948438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.421443</td>\n",
       "      <td>2.830358</td>\n",
       "      <td>0.374458</td>\n",
       "      <td>0.605529</td>\n",
       "      <td>0.769751</td>\n",
       "      <td>1.149873</td>\n",
       "      <td>Real Madrid CF1617</td>\n",
       "      <td>ND</td>\n",
       "      <td>Real Madrid CF1617ND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            club_name         short_name  overall  season best_pos  feature_0  \\\n",
       "43907  Real Madrid CF  Cristiano Ronaldo       94    1718       LW   4.122661   \n",
       "59842        Juventus  Cristiano Ronaldo       94    1819       ST   4.006461   \n",
       "59843    FC Barcelona           L. Messi       94    1819       CF   3.385196   \n",
       "14380    FC Barcelona           L. Messi       94    1516       RW   3.246406   \n",
       "28304  Real Madrid CF  Cristiano Ronaldo       94    1617       LW   4.126410   \n",
       "\n",
       "       feature_1  feature_2  feature_3  feature_4  ...  feature_13  \\\n",
       "43907   1.222620   1.456111        0.0   0.988493  ...         0.0   \n",
       "59842   1.190789   1.405771        0.0   0.936381  ...         0.0   \n",
       "59843   0.747430   2.103769        0.0   2.436939  ...         0.0   \n",
       "14380   0.807521   1.621410        0.0   2.192120  ...         0.0   \n",
       "28304   1.259415   1.360926        0.0   0.948438  ...         0.0   \n",
       "\n",
       "       feature_14  feature_15  feature_16  feature_17  feature_18  feature_19  \\\n",
       "43907    2.423369    2.852642    0.299847    0.576179    0.748574    1.174775   \n",
       "59842    2.313507    2.750958    0.377921    0.566794    0.707652    1.149878   \n",
       "59843    3.431670    2.777207    0.796833    1.467861    1.355075    1.453514   \n",
       "14380    3.447260    2.568624    0.887763    1.365363    1.271545    1.224468   \n",
       "28304    2.421443    2.830358    0.374458    0.605529    0.769751    1.149873   \n",
       "\n",
       "                      key  defender            player_key  \n",
       "43907  Real Madrid CF1718        ND  Real Madrid CF1718ND  \n",
       "59842        Juventus1819        ND        Juventus1819ND  \n",
       "59843    FC Barcelona1819        ND    FC Barcelona1819ND  \n",
       "14380    FC Barcelona1516        ND    FC Barcelona1516ND  \n",
       "28304  Real Madrid CF1617        ND  Real Madrid CF1617ND  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combined player position in cell 6, player details in cell 18, and player embedding into one df\n",
    "#Create a key for each row using club_name and season for team embedding\n",
    "\n",
    "player_embedding_combined = pd.concat([player_details, position.rename('best_pos'), player_embedding], axis=1)\n",
    "player_embedding_combined['key'] = player_embedding_combined['club_name'].astype(str) + player_embedding_combined['season'].astype(str)\n",
    "player_embedding_combined = player_embedding_combined.sort_values(by=['overall'], ascending=False)\n",
    "\n",
    "#Create a column to classify players into defenders and non-defenders based on position\n",
    "#Create a key for each row using club_name, season, and position classification for team embedding\n",
    "def determine_defender(position):\n",
    "    if ((position == 'LWB') or (position == 'LB') or (position == 'LCB') or (position == 'CB') or (position == 'RCB') or (position == 'RB') or (position == 'RWB')):\n",
    "        return \"D\"\n",
    "    else:\n",
    "        return \"ND\"\n",
    "player_embedding_combined['defender'] = player_embedding_combined.apply(lambda x: determine_defender(x['best_pos']), axis=1)\n",
    "player_embedding_combined['player_key'] = player_embedding_combined['key'].astype(str) + player_embedding_combined['defender'].astype(str)\n",
    "player_embedding_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f06c76-f1ac-4d60-aa23-b95f3fa69273",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_embedding_combined_D = player_embedding_combined[player_embedding_combined['defender']==\"D\"]\n",
    "player_embedding_combined_D = player_embedding_combined_D.groupby('player_key').head(8).reset_index(drop=True).sort_values(by=['overall'], ascending=False)\n",
    "\n",
    "player_embedding_combined_ND = player_embedding_combined[player_embedding_combined['defender']==\"ND\"]\n",
    "player_embedding_combined_ND = player_embedding_combined_ND.groupby('player_key').head(12).reset_index(drop=True).sort_values(by=['overall'], ascending=False)\n",
    "\n",
    "player_embedding_combined_D_ND = pd.concat([player_embedding_combined_D, player_embedding_combined_ND])\n",
    "player_embedding_combined_D_ND = player_embedding_combined_D_ND.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab96050-cb65-41b0-be81-663c43b6b9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>club_name</th>\n",
       "      <th>short_name</th>\n",
       "      <th>overall</th>\n",
       "      <th>season</th>\n",
       "      <th>best_pos</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>key</th>\n",
       "      <th>defender</th>\n",
       "      <th>player_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Real Madrid CF</td>\n",
       "      <td>Sergio Ramos</td>\n",
       "      <td>87</td>\n",
       "      <td>1516</td>\n",
       "      <td>CB</td>\n",
       "      <td>2.124804</td>\n",
       "      <td>1.004520</td>\n",
       "      <td>2.782751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.727187</td>\n",
       "      <td>3.042945</td>\n",
       "      <td>1.414106</td>\n",
       "      <td>0.422430</td>\n",
       "      <td>0.595326</td>\n",
       "      <td>0.596105</td>\n",
       "      <td>Real Madrid CF1516</td>\n",
       "      <td>D</td>\n",
       "      <td>Real Madrid CF1516D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Real Madrid CF</td>\n",
       "      <td>Pepe</td>\n",
       "      <td>84</td>\n",
       "      <td>1516</td>\n",
       "      <td>CB</td>\n",
       "      <td>1.780926</td>\n",
       "      <td>0.879123</td>\n",
       "      <td>2.394005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.651587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472614</td>\n",
       "      <td>2.636265</td>\n",
       "      <td>1.413166</td>\n",
       "      <td>1.645054</td>\n",
       "      <td>0.638638</td>\n",
       "      <td>0.748284</td>\n",
       "      <td>Real Madrid CF1516</td>\n",
       "      <td>D</td>\n",
       "      <td>Real Madrid CF1516D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>Real Madrid CF</td>\n",
       "      <td>Marcelo</td>\n",
       "      <td>83</td>\n",
       "      <td>1516</td>\n",
       "      <td>LB</td>\n",
       "      <td>2.201063</td>\n",
       "      <td>1.441615</td>\n",
       "      <td>2.990856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.735173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.852750</td>\n",
       "      <td>2.953912</td>\n",
       "      <td>2.023668</td>\n",
       "      <td>0.549884</td>\n",
       "      <td>0.727022</td>\n",
       "      <td>0.715922</td>\n",
       "      <td>Real Madrid CF1516</td>\n",
       "      <td>D</td>\n",
       "      <td>Real Madrid CF1516D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>Real Madrid CF</td>\n",
       "      <td>R. Varane</td>\n",
       "      <td>82</td>\n",
       "      <td>1516</td>\n",
       "      <td>CB</td>\n",
       "      <td>1.715679</td>\n",
       "      <td>0.281394</td>\n",
       "      <td>2.263497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.749940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.299836</td>\n",
       "      <td>2.450104</td>\n",
       "      <td>1.380157</td>\n",
       "      <td>1.651759</td>\n",
       "      <td>0.636851</td>\n",
       "      <td>0.914882</td>\n",
       "      <td>Real Madrid CF1516</td>\n",
       "      <td>D</td>\n",
       "      <td>Real Madrid CF1516D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>Real Madrid CF</td>\n",
       "      <td>Carvajal</td>\n",
       "      <td>81</td>\n",
       "      <td>1516</td>\n",
       "      <td>RB</td>\n",
       "      <td>1.710597</td>\n",
       "      <td>1.299569</td>\n",
       "      <td>2.356246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.531332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.934706</td>\n",
       "      <td>2.910544</td>\n",
       "      <td>1.234861</td>\n",
       "      <td>0.434099</td>\n",
       "      <td>0.886419</td>\n",
       "      <td>0.469652</td>\n",
       "      <td>Real Madrid CF1516</td>\n",
       "      <td>D</td>\n",
       "      <td>Real Madrid CF1516D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>Real Madrid CF</td>\n",
       "      <td>Danilo</td>\n",
       "      <td>80</td>\n",
       "      <td>1516</td>\n",
       "      <td>RB</td>\n",
       "      <td>2.315021</td>\n",
       "      <td>1.163128</td>\n",
       "      <td>2.015605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.825256</td>\n",
       "      <td>2.858598</td>\n",
       "      <td>1.138036</td>\n",
       "      <td>0.487195</td>\n",
       "      <td>0.339348</td>\n",
       "      <td>0.495871</td>\n",
       "      <td>Real Madrid CF1516</td>\n",
       "      <td>D</td>\n",
       "      <td>Real Madrid CF1516D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>Real Madrid CF</td>\n",
       "      <td>Arbeloa</td>\n",
       "      <td>79</td>\n",
       "      <td>1516</td>\n",
       "      <td>RB</td>\n",
       "      <td>1.647259</td>\n",
       "      <td>0.852351</td>\n",
       "      <td>2.123963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.659760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.358648</td>\n",
       "      <td>2.505687</td>\n",
       "      <td>1.217146</td>\n",
       "      <td>0.974281</td>\n",
       "      <td>0.607974</td>\n",
       "      <td>0.564623</td>\n",
       "      <td>Real Madrid CF1516</td>\n",
       "      <td>D</td>\n",
       "      <td>Real Madrid CF1516D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4384</th>\n",
       "      <td>Real Madrid CF</td>\n",
       "      <td>Nacho Fernández</td>\n",
       "      <td>75</td>\n",
       "      <td>1516</td>\n",
       "      <td>CB</td>\n",
       "      <td>1.205409</td>\n",
       "      <td>0.539433</td>\n",
       "      <td>2.276125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600022</td>\n",
       "      <td>2.075383</td>\n",
       "      <td>1.417974</td>\n",
       "      <td>0.879538</td>\n",
       "      <td>0.616044</td>\n",
       "      <td>0.499204</td>\n",
       "      <td>Real Madrid CF1516</td>\n",
       "      <td>D</td>\n",
       "      <td>Real Madrid CF1516D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39985</th>\n",
       "      <td>Real Madrid CF</td>\n",
       "      <td>Cristiano Ronaldo</td>\n",
       "      <td>93</td>\n",
       "      <td>1516</td>\n",
       "      <td>LW</td>\n",
       "      <td>3.953484</td>\n",
       "      <td>1.234891</td>\n",
       "      <td>1.221004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.894786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.346539</td>\n",
       "      <td>2.661075</td>\n",
       "      <td>0.461978</td>\n",
       "      <td>0.602689</td>\n",
       "      <td>0.593610</td>\n",
       "      <td>1.076918</td>\n",
       "      <td>Real Madrid CF1516</td>\n",
       "      <td>ND</td>\n",
       "      <td>Real Madrid CF1516ND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40123</th>\n",
       "      <td>Real Madrid CF</td>\n",
       "      <td>L. Modrić</td>\n",
       "      <td>87</td>\n",
       "      <td>1516</td>\n",
       "      <td>CM</td>\n",
       "      <td>2.269099</td>\n",
       "      <td>1.143761</td>\n",
       "      <td>2.227264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.282948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.606233</td>\n",
       "      <td>3.258205</td>\n",
       "      <td>0.348104</td>\n",
       "      <td>0.528267</td>\n",
       "      <td>0.569568</td>\n",
       "      <td>0.815508</td>\n",
       "      <td>Real Madrid CF1516</td>\n",
       "      <td>ND</td>\n",
       "      <td>Real Madrid CF1516ND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40125</th>\n",
       "      <td>Real Madrid CF</td>\n",
       "      <td>T. Kroos</td>\n",
       "      <td>87</td>\n",
       "      <td>1516</td>\n",
       "      <td>CM</td>\n",
       "      <td>2.206789</td>\n",
       "      <td>0.734216</td>\n",
       "      <td>2.940313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.020327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.935811</td>\n",
       "      <td>2.198300</td>\n",
       "      <td>0.879499</td>\n",
       "      <td>0.909333</td>\n",
       "      <td>0.320066</td>\n",
       "      <td>0.782653</td>\n",
       "      <td>Real Madrid CF1516</td>\n",
       "      <td>ND</td>\n",
       "      <td>Real Madrid CF1516ND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40139</th>\n",
       "      <td>Real Madrid CF</td>\n",
       "      <td>G. Bale</td>\n",
       "      <td>87</td>\n",
       "      <td>1516</td>\n",
       "      <td>RM</td>\n",
       "      <td>3.103000</td>\n",
       "      <td>1.445725</td>\n",
       "      <td>2.090477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.041909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.111132</td>\n",
       "      <td>3.034411</td>\n",
       "      <td>1.750877</td>\n",
       "      <td>0.825395</td>\n",
       "      <td>0.326958</td>\n",
       "      <td>0.702157</td>\n",
       "      <td>Real Madrid CF1516</td>\n",
       "      <td>ND</td>\n",
       "      <td>Real Madrid CF1516ND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40155</th>\n",
       "      <td>Real Madrid CF</td>\n",
       "      <td>J. Rodríguez</td>\n",
       "      <td>87</td>\n",
       "      <td>1516</td>\n",
       "      <td>CAM</td>\n",
       "      <td>2.698495</td>\n",
       "      <td>1.204168</td>\n",
       "      <td>2.276838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.779803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.762593</td>\n",
       "      <td>2.116851</td>\n",
       "      <td>0.989562</td>\n",
       "      <td>1.214409</td>\n",
       "      <td>0.527083</td>\n",
       "      <td>0.802374</td>\n",
       "      <td>Real Madrid CF1516</td>\n",
       "      <td>ND</td>\n",
       "      <td>Real Madrid CF1516ND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40203</th>\n",
       "      <td>Real Madrid CF</td>\n",
       "      <td>K. Benzema</td>\n",
       "      <td>86</td>\n",
       "      <td>1516</td>\n",
       "      <td>ST</td>\n",
       "      <td>3.000237</td>\n",
       "      <td>1.082116</td>\n",
       "      <td>1.339637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.691940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.414475</td>\n",
       "      <td>1.628704</td>\n",
       "      <td>0.440311</td>\n",
       "      <td>1.128796</td>\n",
       "      <td>0.826495</td>\n",
       "      <td>0.853146</td>\n",
       "      <td>Real Madrid CF1516</td>\n",
       "      <td>ND</td>\n",
       "      <td>Real Madrid CF1516ND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40439</th>\n",
       "      <td>Real Madrid CF</td>\n",
       "      <td>Isco</td>\n",
       "      <td>84</td>\n",
       "      <td>1516</td>\n",
       "      <td>CAM</td>\n",
       "      <td>2.117014</td>\n",
       "      <td>1.253581</td>\n",
       "      <td>1.704379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.737353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.123998</td>\n",
       "      <td>2.094357</td>\n",
       "      <td>0.108710</td>\n",
       "      <td>0.488680</td>\n",
       "      <td>0.533764</td>\n",
       "      <td>0.752004</td>\n",
       "      <td>Real Madrid CF1516</td>\n",
       "      <td>ND</td>\n",
       "      <td>Real Madrid CF1516ND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44009</th>\n",
       "      <td>Real Madrid CF</td>\n",
       "      <td>D. Cheryshev</td>\n",
       "      <td>78</td>\n",
       "      <td>1516</td>\n",
       "      <td>LM</td>\n",
       "      <td>2.059325</td>\n",
       "      <td>1.208827</td>\n",
       "      <td>1.799618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.987521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.686563</td>\n",
       "      <td>2.321998</td>\n",
       "      <td>1.424995</td>\n",
       "      <td>0.417252</td>\n",
       "      <td>0.446633</td>\n",
       "      <td>0.583760</td>\n",
       "      <td>Real Madrid CF1516</td>\n",
       "      <td>ND</td>\n",
       "      <td>Real Madrid CF1516ND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44011</th>\n",
       "      <td>Real Madrid CF</td>\n",
       "      <td>M. Kovačić</td>\n",
       "      <td>78</td>\n",
       "      <td>1516</td>\n",
       "      <td>CM</td>\n",
       "      <td>1.922718</td>\n",
       "      <td>0.940607</td>\n",
       "      <td>2.054862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.667077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.369252</td>\n",
       "      <td>2.036619</td>\n",
       "      <td>0.548365</td>\n",
       "      <td>1.163440</td>\n",
       "      <td>0.188263</td>\n",
       "      <td>0.878546</td>\n",
       "      <td>Real Madrid CF1516</td>\n",
       "      <td>ND</td>\n",
       "      <td>Real Madrid CF1516ND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44066</th>\n",
       "      <td>Real Madrid CF</td>\n",
       "      <td>Jesé</td>\n",
       "      <td>78</td>\n",
       "      <td>1516</td>\n",
       "      <td>LM</td>\n",
       "      <td>1.990143</td>\n",
       "      <td>0.371065</td>\n",
       "      <td>0.998131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.712503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.353777</td>\n",
       "      <td>1.410763</td>\n",
       "      <td>0.528121</td>\n",
       "      <td>0.818260</td>\n",
       "      <td>0.319458</td>\n",
       "      <td>0.851381</td>\n",
       "      <td>Real Madrid CF1516</td>\n",
       "      <td>ND</td>\n",
       "      <td>Real Madrid CF1516ND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44541</th>\n",
       "      <td>Real Madrid CF</td>\n",
       "      <td>Casemiro</td>\n",
       "      <td>77</td>\n",
       "      <td>1516</td>\n",
       "      <td>CDM</td>\n",
       "      <td>2.278827</td>\n",
       "      <td>0.494094</td>\n",
       "      <td>2.256809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.757794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.832652</td>\n",
       "      <td>2.339937</td>\n",
       "      <td>0.669007</td>\n",
       "      <td>1.475179</td>\n",
       "      <td>0.451381</td>\n",
       "      <td>0.565013</td>\n",
       "      <td>Real Madrid CF1516</td>\n",
       "      <td>ND</td>\n",
       "      <td>Real Madrid CF1516ND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46773</th>\n",
       "      <td>Real Madrid CF</td>\n",
       "      <td>Lucas Vázquez</td>\n",
       "      <td>76</td>\n",
       "      <td>1516</td>\n",
       "      <td>RM</td>\n",
       "      <td>1.697349</td>\n",
       "      <td>1.090160</td>\n",
       "      <td>1.223948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.849749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.106043</td>\n",
       "      <td>1.504306</td>\n",
       "      <td>0.559523</td>\n",
       "      <td>0.329844</td>\n",
       "      <td>0.824281</td>\n",
       "      <td>0.198109</td>\n",
       "      <td>Real Madrid CF1516</td>\n",
       "      <td>ND</td>\n",
       "      <td>Real Madrid CF1516ND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            club_name         short_name  overall  season best_pos  feature_0  \\\n",
       "43     Real Madrid CF       Sergio Ramos       87    1516       CB   2.124804   \n",
       "168    Real Madrid CF               Pepe       84    1516       CB   1.780926   \n",
       "322    Real Madrid CF            Marcelo       83    1516       LB   2.201063   \n",
       "428    Real Madrid CF          R. Varane       82    1516       CB   1.715679   \n",
       "694    Real Madrid CF           Carvajal       81    1516       RB   1.710597   \n",
       "819    Real Madrid CF             Danilo       80    1516       RB   2.315021   \n",
       "1273   Real Madrid CF            Arbeloa       79    1516       RB   1.647259   \n",
       "4384   Real Madrid CF    Nacho Fernández       75    1516       CB   1.205409   \n",
       "39985  Real Madrid CF  Cristiano Ronaldo       93    1516       LW   3.953484   \n",
       "40123  Real Madrid CF          L. Modrić       87    1516       CM   2.269099   \n",
       "40125  Real Madrid CF           T. Kroos       87    1516       CM   2.206789   \n",
       "40139  Real Madrid CF            G. Bale       87    1516       RM   3.103000   \n",
       "40155  Real Madrid CF       J. Rodríguez       87    1516      CAM   2.698495   \n",
       "40203  Real Madrid CF         K. Benzema       86    1516       ST   3.000237   \n",
       "40439  Real Madrid CF               Isco       84    1516      CAM   2.117014   \n",
       "44009  Real Madrid CF       D. Cheryshev       78    1516       LM   2.059325   \n",
       "44011  Real Madrid CF         M. Kovačić       78    1516       CM   1.922718   \n",
       "44066  Real Madrid CF               Jesé       78    1516       LM   1.990143   \n",
       "44541  Real Madrid CF           Casemiro       77    1516      CDM   2.278827   \n",
       "46773  Real Madrid CF      Lucas Vázquez       76    1516       RM   1.697349   \n",
       "\n",
       "       feature_1  feature_2  feature_3  feature_4  ...  feature_13  \\\n",
       "43      1.004520   2.782751        0.0   0.150618  ...         0.0   \n",
       "168     0.879123   2.394005        0.0   0.651587  ...         0.0   \n",
       "322     1.441615   2.990856        0.0   1.735173  ...         0.0   \n",
       "428     0.281394   2.263497        0.0   0.749940  ...         0.0   \n",
       "694     1.299569   2.356246        0.0   0.531332  ...         0.0   \n",
       "819     1.163128   2.015605        0.0   0.857278  ...         0.0   \n",
       "1273    0.852351   2.123963        0.0   0.659760  ...         0.0   \n",
       "4384    0.539433   2.276125        0.0   0.412004  ...         0.0   \n",
       "39985   1.234891   1.221004        0.0   0.894786  ...         0.0   \n",
       "40123   1.143761   2.227264        0.0   1.282948  ...         0.0   \n",
       "40125   0.734216   2.940313        0.0   2.020327  ...         0.0   \n",
       "40139   1.445725   2.090477        0.0   2.041909  ...         0.0   \n",
       "40155   1.204168   2.276838        0.0   1.779803  ...         0.0   \n",
       "40203   1.082116   1.339637        0.0   0.691940  ...         0.0   \n",
       "40439   1.253581   1.704379        0.0   0.737353  ...         0.0   \n",
       "44009   1.208827   1.799618        0.0   1.987521  ...         0.0   \n",
       "44011   0.940607   2.054862        0.0   0.667077  ...         0.0   \n",
       "44066   0.371065   0.998131        0.0   0.712503  ...         0.0   \n",
       "44541   0.494094   2.256809        0.0   0.757794  ...         0.0   \n",
       "46773   1.090160   1.223948        0.0   0.849749  ...         0.0   \n",
       "\n",
       "       feature_14  feature_15  feature_16  feature_17  feature_18  feature_19  \\\n",
       "43       0.727187    3.042945    1.414106    0.422430    0.595326    0.596105   \n",
       "168      0.472614    2.636265    1.413166    1.645054    0.638638    0.748284   \n",
       "322      1.852750    2.953912    2.023668    0.549884    0.727022    0.715922   \n",
       "428      0.299836    2.450104    1.380157    1.651759    0.636851    0.914882   \n",
       "694      0.934706    2.910544    1.234861    0.434099    0.886419    0.469652   \n",
       "819      0.825256    2.858598    1.138036    0.487195    0.339348    0.495871   \n",
       "1273     0.358648    2.505687    1.217146    0.974281    0.607974    0.564623   \n",
       "4384     0.600022    2.075383    1.417974    0.879538    0.616044    0.499204   \n",
       "39985    2.346539    2.661075    0.461978    0.602689    0.593610    1.076918   \n",
       "40123    1.606233    3.258205    0.348104    0.528267    0.569568    0.815508   \n",
       "40125    1.935811    2.198300    0.879499    0.909333    0.320066    0.782653   \n",
       "40139    2.111132    3.034411    1.750877    0.825395    0.326958    0.702157   \n",
       "40155    2.762593    2.116851    0.989562    1.214409    0.527083    0.802374   \n",
       "40203    2.414475    1.628704    0.440311    1.128796    0.826495    0.853146   \n",
       "40439    2.123998    2.094357    0.108710    0.488680    0.533764    0.752004   \n",
       "44009    1.686563    2.321998    1.424995    0.417252    0.446633    0.583760   \n",
       "44011    2.369252    2.036619    0.548365    1.163440    0.188263    0.878546   \n",
       "44066    2.353777    1.410763    0.528121    0.818260    0.319458    0.851381   \n",
       "44541    0.832652    2.339937    0.669007    1.475179    0.451381    0.565013   \n",
       "46773    2.106043    1.504306    0.559523    0.329844    0.824281    0.198109   \n",
       "\n",
       "                      key  defender            player_key  \n",
       "43     Real Madrid CF1516         D   Real Madrid CF1516D  \n",
       "168    Real Madrid CF1516         D   Real Madrid CF1516D  \n",
       "322    Real Madrid CF1516         D   Real Madrid CF1516D  \n",
       "428    Real Madrid CF1516         D   Real Madrid CF1516D  \n",
       "694    Real Madrid CF1516         D   Real Madrid CF1516D  \n",
       "819    Real Madrid CF1516         D   Real Madrid CF1516D  \n",
       "1273   Real Madrid CF1516         D   Real Madrid CF1516D  \n",
       "4384   Real Madrid CF1516         D   Real Madrid CF1516D  \n",
       "39985  Real Madrid CF1516        ND  Real Madrid CF1516ND  \n",
       "40123  Real Madrid CF1516        ND  Real Madrid CF1516ND  \n",
       "40125  Real Madrid CF1516        ND  Real Madrid CF1516ND  \n",
       "40139  Real Madrid CF1516        ND  Real Madrid CF1516ND  \n",
       "40155  Real Madrid CF1516        ND  Real Madrid CF1516ND  \n",
       "40203  Real Madrid CF1516        ND  Real Madrid CF1516ND  \n",
       "40439  Real Madrid CF1516        ND  Real Madrid CF1516ND  \n",
       "44009  Real Madrid CF1516        ND  Real Madrid CF1516ND  \n",
       "44011  Real Madrid CF1516        ND  Real Madrid CF1516ND  \n",
       "44066  Real Madrid CF1516        ND  Real Madrid CF1516ND  \n",
       "44541  Real Madrid CF1516        ND  Real Madrid CF1516ND  \n",
       "46773  Real Madrid CF1516        ND  Real Madrid CF1516ND  \n",
       "\n",
       "[20 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_embedding_combined_D_ND[player_embedding_combined_D_ND['key'].str.contains('Real Madrid CF1516')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb67cb53-7dc4-43e9-8e3a-c25496de882c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>392</th>\n",
       "      <th>393</th>\n",
       "      <th>394</th>\n",
       "      <th>395</th>\n",
       "      <th>396</th>\n",
       "      <th>397</th>\n",
       "      <th>398</th>\n",
       "      <th>399</th>\n",
       "      <th>team</th>\n",
       "      <th>league_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.212532</td>\n",
       "      <td>0.661989</td>\n",
       "      <td>2.436652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.959036</td>\n",
       "      <td>1.704753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.059886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.212796</td>\n",
       "      <td>1.270461</td>\n",
       "      <td>0.668045</td>\n",
       "      <td>1.028716</td>\n",
       "      <td>0.565971</td>\n",
       "      <td>0.610142</td>\n",
       "      <td>Zagłębie Lubin2021</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.276283</td>\n",
       "      <td>0.546805</td>\n",
       "      <td>2.360179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.650562</td>\n",
       "      <td>1.616852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.740669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.936555</td>\n",
       "      <td>1.672078</td>\n",
       "      <td>0.710642</td>\n",
       "      <td>0.922031</td>\n",
       "      <td>0.545203</td>\n",
       "      <td>0.685204</td>\n",
       "      <td>Derby County1920</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.341418</td>\n",
       "      <td>1.037563</td>\n",
       "      <td>2.507438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.893255</td>\n",
       "      <td>1.596647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.244697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.316056</td>\n",
       "      <td>1.583573</td>\n",
       "      <td>0.618122</td>\n",
       "      <td>1.003232</td>\n",
       "      <td>0.497168</td>\n",
       "      <td>0.694642</td>\n",
       "      <td>Dijon FCO2122</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.507499</td>\n",
       "      <td>1.123514</td>\n",
       "      <td>1.980241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.435500</td>\n",
       "      <td>1.291182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.077614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.881724</td>\n",
       "      <td>1.155251</td>\n",
       "      <td>0.604587</td>\n",
       "      <td>0.895576</td>\n",
       "      <td>0.407969</td>\n",
       "      <td>0.502002</td>\n",
       "      <td>Barnsley1718</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.899354</td>\n",
       "      <td>1.089398</td>\n",
       "      <td>2.346075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.944487</td>\n",
       "      <td>0.626924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.713100</td>\n",
       "      <td>1.345427</td>\n",
       "      <td>1.580029</td>\n",
       "      <td>0.311806</td>\n",
       "      <td>0.466192</td>\n",
       "      <td>0.811964</td>\n",
       "      <td>CF Monterrey1920</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2    3         4         5    6    7         8  \\\n",
       "0  1.212532  0.661989  2.436652  0.0  0.959036  1.704753  0.0  0.0  1.059886   \n",
       "1  1.276283  0.546805  2.360179  0.0  0.650562  1.616852  0.0  0.0  0.740669   \n",
       "2  1.341418  1.037563  2.507438  0.0  0.893255  1.596647  0.0  0.0  1.244697   \n",
       "3  1.507499  1.123514  1.980241  0.0  0.435500  1.291182  0.0  0.0  1.077614   \n",
       "4  1.899354  1.089398  2.346075  0.0  1.944487  0.626924  0.0  0.0  0.115714   \n",
       "\n",
       "     9  ...  392  393       394       395       396       397       398  \\\n",
       "0  0.0  ...  0.0  0.0  1.212796  1.270461  0.668045  1.028716  0.565971   \n",
       "1  0.0  ...  0.0  0.0  0.936555  1.672078  0.710642  0.922031  0.545203   \n",
       "2  0.0  ...  0.0  0.0  1.316056  1.583573  0.618122  1.003232  0.497168   \n",
       "3  0.0  ...  0.0  0.0  0.881724  1.155251  0.604587  0.895576  0.407969   \n",
       "4  0.0  ...  0.0  0.0  1.713100  1.345427  1.580029  0.311806  0.466192   \n",
       "\n",
       "        399                team  league_level  \n",
       "0  0.610142  Zagłębie Lubin2021           0.2  \n",
       "1  0.685204    Derby County1920           0.4  \n",
       "2  0.694642       Dijon FCO2122           0.4  \n",
       "3  0.502002        Barnsley1718           0.4  \n",
       "4  0.811964    CF Monterrey1920           0.2  \n",
       "\n",
       "[5 rows x 402 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Flatten the df with 20 players to a single row with (20 * number of dimensions in player embeddings) columns\n",
    "team_season_set = set(player_embedding_combined['key'].tolist())\n",
    "all_teams_df = pd.DataFrame()\n",
    "\n",
    "for team in team_season_set:\n",
    "    team_df = player_embedding_combined_D_ND[player_embedding_combined_D_ND['key']==team]\n",
    "    team_df = team_df.drop(['best_pos','club_name','short_name','overall','season','key','defender','player_key'], axis=1)\n",
    "    team_row = team_df.stack().reset_index().drop(['level_0','level_1'],axis=1).transpose()\n",
    "    all_teams_df = pd.concat([all_teams_df, team_row])\n",
    "#display(all_teams_df)\n",
    "\n",
    "#player_embedding_combined_D_ND[player_embedding_combined_D_ND['key']=='Cork City1718']\n",
    "all_teams_df['team'] = list(team_season_set)\n",
    "all_teams_df = all_teams_df.dropna()\n",
    "teams = all_teams_df['team']\n",
    "\n",
    "#This cell and the cell below are optional (this is to add the league level to the team embeddings as a seaprate feature)\n",
    "league_level_info = df[['club_name', 'season', 'league_level']]\n",
    "league_level_info['key'] = league_level_info['club_name'].astype(str) + league_level_info['season'].astype(str)\n",
    "league_level_info = league_level_info.drop(['club_name','season'],axis=1)\n",
    "league_level_info = league_level_info.rename(columns={\"key\": \"team\"})\n",
    "league_level_info['league_level'] = league_level_info['league_level']/5\n",
    "league_level_info = league_level_info.drop_duplicates()\n",
    "\n",
    "all_teams_df = all_teams_df.merge(league_level_info, on=\"team\", how=\"left\")\n",
    "all_teams_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1c1cac-21a5-4a32-bc4e-5c8344a88d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  FutureWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "all_teams_df = all_teams_df.drop(['team'], axis=1)\n",
    "teamscaler = MinMaxScaler()\n",
    "X = teamscaler.fit_transform(all_teams_df)\n",
    "y = all_teams_df['league_level']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63ca0bd-0fd5-4ed0-a43d-a4f43fa3d30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_large_nn(emb_dim = 50, epochs=100, batch_size=32):\n",
    "    input = tf.keras.layers.Input(shape=X_train.shape[1:])\n",
    "\n",
    "    encoder = tf.keras.layers.Dense(X_train.shape[1:][0], activation='relu')(input)\n",
    "    encoder = tf.keras.layers.Dense(375, activation='relu')(encoder)\n",
    "    encoder = tf.keras.layers.Dense(350, activation='relu')(encoder)\n",
    "    encoder = tf.keras.layers.Dense(325, activation='relu')(encoder)\n",
    "    encoder = tf.keras.layers.Dense(300, activation='relu')(encoder)\n",
    "    encoder = tf.keras.layers.Dense(275, activation='relu')(encoder)\n",
    "    encoder = tf.keras.layers.Dense(250, activation='relu')(encoder)\n",
    "    encoder = tf.keras.layers.Dense(225, activation='relu')(encoder)\n",
    "    encoder = tf.keras.layers.Dense(200, activation='relu')(encoder)\n",
    "    encoder = tf.keras.layers.Dense(175, activation='relu')(encoder)\n",
    "    encoder = tf.keras.layers.Dense(150, activation='relu')(encoder)\n",
    "    encoder = tf.keras.layers.Dense(125, activation='relu')(encoder)\n",
    "    encoder = tf.keras.layers.Dense(100, activation='relu')(encoder)\n",
    "    encoder = tf.keras.layers.Dense(75, activation='relu')(encoder)\n",
    "    embedding = tf.keras.layers.Dense(emb_dim, activation='relu',name='embedding')(encoder)\n",
    "\n",
    "    decoder = tf.keras.layers.Dense(75, activation='relu')(embedding)\n",
    "    decoder = tf.keras.layers.Dense(100, activation='relu')(decoder)\n",
    "    decoder = tf.keras.layers.Dense(125, activation='relu')(decoder)\n",
    "    decoder = tf.keras.layers.Dense(150, activation='relu')(decoder)\n",
    "    decoder = tf.keras.layers.Dense(175, activation='relu')(decoder)\n",
    "    decoder = tf.keras.layers.Dense(200, activation='relu')(decoder)\n",
    "    decoder = tf.keras.layers.Dense(225, activation='relu')(decoder)\n",
    "    decoder = tf.keras.layers.Dense(250, activation='relu')(decoder)\n",
    "    decoder = tf.keras.layers.Dense(275, activation='relu')(decoder)\n",
    "    decoder = tf.keras.layers.Dense(300, activation='relu')(decoder)\n",
    "    decoder = tf.keras.layers.Dense(325, activation='relu')(decoder)\n",
    "    decoder = tf.keras.layers.Dense(350, activation='relu')(decoder)\n",
    "    decoder = tf.keras.layers.Dense(375, activation='relu')(decoder)\n",
    "    decoder = tf.keras.layers.Dense(X_train.shape[1], activation='sigmoid')(decoder),\n",
    "\n",
    "    autoencoder = Model(input, decoder)\n",
    "    autoencoder.compile(loss='mae', optimizer='adam')\n",
    "    callback = EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "    history = autoencoder.fit(X_train, X_train, epochs=epochs, batch_size=batch_size, validation_split=0.1, #shuffle=False, \n",
    "                    callbacks=[callback], validation_data = (X_test, X_test))\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0674015c-4e80-4ebc-a621-98aaa665667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_small_nn(emb_dim = 50, epochs=100, batch_size=32):\n",
    "    input = tf.keras.layers.Input(shape=X_train.shape[1:])\n",
    "\n",
    "    encoder = tf.keras.layers.Dense(X_train.shape[1:][0], activation='relu')(input)\n",
    "    encoder = tf.keras.layers.Dense(350, activation='relu')(encoder)\n",
    "    encoder = tf.keras.layers.Dense(300, activation='relu')(encoder)\n",
    "    encoder = tf.keras.layers.Dense(250, activation='relu')(encoder)\n",
    "    encoder = tf.keras.layers.Dense(200, activation='relu')(encoder)\n",
    "    encoder = tf.keras.layers.Dense(150, activation='relu')(encoder)\n",
    "    encoder = tf.keras.layers.Dense(100, activation='relu')(encoder)\n",
    "    embedding = tf.keras.layers.Dense(emb_dim, activation='relu',name='embedding')(encoder)\n",
    "\n",
    "    decoder = tf.keras.layers.Dense(100, activation='relu')(embedding)\n",
    "    decoder = tf.keras.layers.Dense(150, activation='relu')(decoder)\n",
    "    decoder = tf.keras.layers.Dense(200, activation='relu')(decoder)\n",
    "    decoder = tf.keras.layers.Dense(250, activation='relu')(decoder)\n",
    "    decoder = tf.keras.layers.Dense(300, activation='relu')(decoder)\n",
    "    decoder = tf.keras.layers.Dense(350, activation='relu')(decoder)\n",
    "    decoder = tf.keras.layers.Dense(X_train.shape[1], activation='sigmoid')(decoder),\n",
    "    \n",
    "    autoencoder = Model(input, decoder)\n",
    "    autoencoder.compile(loss='mae', optimizer='adam')\n",
    "    callback = EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "    history = autoencoder.fit(X_train, X_train, epochs=epochs, batch_size=batch_size, validation_split=0.1, #shuffle=False, \n",
    "                    callbacks=[callback], validation_data = (X_test, X_test))\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609a6158-9dfc-4513-8aeb-c19c17a0586f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training with Latent Space Dimension for Large NN: 30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 16:25:15.102570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-21 16:25:15.532487: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-21 16:25:15.534446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-21 16:25:15.563025: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-21 16:25:15.564072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-21 16:25:15.565858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-21 16:25:15.567599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-21 16:25:20.236518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-21 16:25:20.259446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-21 16:25:20.261269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-21 16:25:20.263030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13584 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "108/108 [==============================] - 8s 9ms/step - loss: 0.1145 - val_loss: 0.0886\n",
      "Epoch 2/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0895 - val_loss: 0.0883\n",
      "Epoch 3/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0891 - val_loss: 0.0876\n",
      "Epoch 4/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0881 - val_loss: 0.0858\n",
      "Epoch 5/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0859 - val_loss: 0.0843\n",
      "Epoch 6/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0852 - val_loss: 0.0841\n",
      "Epoch 7/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0849 - val_loss: 0.0845\n",
      "Epoch 8/100\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0848 - val_loss: 0.0839\n",
      "Epoch 9/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0848 - val_loss: 0.0841\n",
      "Epoch 10/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0846 - val_loss: 0.0838\n",
      "Epoch 11/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0846 - val_loss: 0.0841\n",
      "Epoch 12/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0845 - val_loss: 0.0838\n",
      "Epoch 13/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0845 - val_loss: 0.0838\n",
      "Epoch 14/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0844 - val_loss: 0.0838\n",
      "Epoch 15/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0844 - val_loss: 0.0838\n",
      "Epoch 16/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0844 - val_loss: 0.0839\n",
      "Epoch 17/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0844 - val_loss: 0.0837\n",
      "Epoch 18/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0843 - val_loss: 0.0837\n",
      "Epoch 19/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0843 - val_loss: 0.0837\n",
      "Epoch 20/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0843 - val_loss: 0.0836\n",
      "Epoch 21/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0843 - val_loss: 0.0838\n",
      "Epoch 22/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0844 - val_loss: 0.0837\n",
      "Epoch 23/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0843 - val_loss: 0.0837\n",
      "Epoch 24/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 25/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0843 - val_loss: 0.0837\n",
      "Epoch 26/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0843 - val_loss: 0.0836\n",
      "Epoch 27/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0839\n",
      "Epoch 28/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0835\n",
      "Epoch 29/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 30/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0838\n",
      "Epoch 31/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0837\n",
      "Epoch 32/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0838\n",
      "Epoch 33/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0835\n",
      "Epoch 34/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0837\n",
      "Epoch 35/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0841 - val_loss: 0.0836\n",
      "Epoch 36/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0841 - val_loss: 0.0836\n",
      "Epoch 37/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 38/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 39/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Completed Training with Latent Space Dimension for Large NN: 30\n",
      "\n",
      "\n",
      "Start Training with Latent Space Dimension for Large NN: 40\n",
      "\n",
      "Epoch 1/100\n",
      "108/108 [==============================] - 2s 9ms/step - loss: 0.1180 - val_loss: 0.0885\n",
      "Epoch 2/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0897 - val_loss: 0.0878\n",
      "Epoch 3/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0891 - val_loss: 0.0876\n",
      "Epoch 4/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0884 - val_loss: 0.0853\n",
      "Epoch 5/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0856 - val_loss: 0.0844\n",
      "Epoch 6/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0851 - val_loss: 0.0842\n",
      "Epoch 7/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0849 - val_loss: 0.0839\n",
      "Epoch 8/100\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.0848 - val_loss: 0.0840\n",
      "Epoch 9/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0847 - val_loss: 0.0840\n",
      "Epoch 10/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0846 - val_loss: 0.0839\n",
      "Epoch 11/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0845 - val_loss: 0.0839\n",
      "Epoch 12/100\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0845 - val_loss: 0.0840\n",
      "Epoch 13/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0845 - val_loss: 0.0837\n",
      "Epoch 14/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0844 - val_loss: 0.0839\n",
      "Epoch 15/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0844 - val_loss: 0.0837\n",
      "Epoch 16/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0844 - val_loss: 0.0837\n",
      "Epoch 17/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0844 - val_loss: 0.0837\n",
      "Epoch 18/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0843 - val_loss: 0.0837\n",
      "Epoch 19/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0843 - val_loss: 0.0837\n",
      "Epoch 20/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0843 - val_loss: 0.0837\n",
      "Epoch 21/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0843 - val_loss: 0.0837\n",
      "Epoch 22/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 23/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 24/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 25/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 26/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 27/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 28/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 29/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 30/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0841 - val_loss: 0.0837\n",
      "Epoch 31/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0841 - val_loss: 0.0836\n",
      "Epoch 32/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0841 - val_loss: 0.0836\n",
      "Epoch 33/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0841 - val_loss: 0.0836\n",
      "Epoch 34/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 35/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 36/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0841 - val_loss: 0.0836\n",
      "Epoch 37/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0841 - val_loss: 0.0835\n",
      "Epoch 38/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0841 - val_loss: 0.0836\n",
      "Epoch 39/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0835\n",
      "Completed Training with Latent Space Dimension for Large NN: 40\n",
      "\n",
      "\n",
      "Start Training with Latent Space Dimension for Large NN: 50\n",
      "\n",
      "Epoch 1/100\n",
      "108/108 [==============================] - 2s 9ms/step - loss: 0.1124 - val_loss: 0.0885\n",
      "Epoch 2/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0894 - val_loss: 0.0882\n",
      "Epoch 3/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0890 - val_loss: 0.0876\n",
      "Epoch 4/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0870 - val_loss: 0.0846\n",
      "Epoch 5/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0853 - val_loss: 0.0844\n",
      "Epoch 6/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0852 - val_loss: 0.0843\n",
      "Epoch 7/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0850 - val_loss: 0.0845\n",
      "Epoch 8/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0849 - val_loss: 0.0840\n",
      "Epoch 9/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0848 - val_loss: 0.0840\n",
      "Epoch 10/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0847 - val_loss: 0.0840\n",
      "Epoch 11/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0846 - val_loss: 0.0839\n",
      "Epoch 12/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0845 - val_loss: 0.0838\n",
      "Epoch 13/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0846 - val_loss: 0.0839\n",
      "Epoch 14/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0845 - val_loss: 0.0838\n",
      "Epoch 15/100\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0844 - val_loss: 0.0837\n",
      "Epoch 16/100\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0844 - val_loss: 0.0838\n",
      "Epoch 17/100\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0844 - val_loss: 0.0837\n",
      "Epoch 18/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0843 - val_loss: 0.0837\n",
      "Epoch 19/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0844 - val_loss: 0.0836\n",
      "Epoch 20/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0843 - val_loss: 0.0838\n",
      "Epoch 21/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0843 - val_loss: 0.0837\n",
      "Epoch 22/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0844 - val_loss: 0.0837\n",
      "Epoch 23/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0843 - val_loss: 0.0838\n",
      "Epoch 24/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0843 - val_loss: 0.0836\n",
      "Epoch 25/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 26/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 27/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 28/100\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0843 - val_loss: 0.0837\n",
      "Epoch 29/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0837\n",
      "Epoch 30/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 31/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 32/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 33/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 34/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0837\n",
      "Epoch 35/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 36/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0841 - val_loss: 0.0836\n",
      "Epoch 37/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0841 - val_loss: 0.0835\n",
      "Epoch 38/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0841 - val_loss: 0.0836\n",
      "Epoch 39/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0841 - val_loss: 0.0836\n",
      "Epoch 40/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0841 - val_loss: 0.0835\n",
      "Epoch 41/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0841 - val_loss: 0.0836\n",
      "Epoch 42/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0841 - val_loss: 0.0837\n",
      "Epoch 43/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0838\n",
      "Epoch 44/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0841 - val_loss: 0.0836\n",
      "Completed Training with Latent Space Dimension for Large NN: 50\n",
      "\n",
      "\n",
      "Start Training with Latent Space Dimension for Small NN: 30\n",
      "\n",
      "Epoch 1/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1081 - val_loss: 0.0888\n",
      "Epoch 2/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0895 - val_loss: 0.0883\n",
      "Epoch 3/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0891 - val_loss: 0.0876\n",
      "Epoch 4/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0867 - val_loss: 0.0846\n",
      "Epoch 5/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0851 - val_loss: 0.0842\n",
      "Epoch 6/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0848 - val_loss: 0.0840\n",
      "Epoch 7/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0846 - val_loss: 0.0839\n",
      "Epoch 8/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0845 - val_loss: 0.0839\n",
      "Epoch 9/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0845 - val_loss: 0.0837\n",
      "Epoch 10/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0843 - val_loss: 0.0836\n",
      "Epoch 11/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0843 - val_loss: 0.0836\n",
      "Epoch 12/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0842 - val_loss: 0.0835\n",
      "Epoch 13/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0842 - val_loss: 0.0835\n",
      "Epoch 14/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0842 - val_loss: 0.0835\n",
      "Epoch 15/100\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0841 - val_loss: 0.0837\n",
      "Epoch 16/100\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0841 - val_loss: 0.0836\n",
      "Epoch 17/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0840 - val_loss: 0.0834\n",
      "Epoch 18/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0840 - val_loss: 0.0834\n",
      "Epoch 19/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0840 - val_loss: 0.0835\n",
      "Epoch 20/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0840 - val_loss: 0.0834\n",
      "Epoch 21/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0839 - val_loss: 0.0833\n",
      "Epoch 22/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0838 - val_loss: 0.0833\n",
      "Epoch 23/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0838 - val_loss: 0.0833\n",
      "Epoch 24/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0837 - val_loss: 0.0832\n",
      "Epoch 25/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0836 - val_loss: 0.0831\n",
      "Epoch 26/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0836 - val_loss: 0.0831\n",
      "Epoch 27/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0834 - val_loss: 0.0830\n",
      "Epoch 28/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0834 - val_loss: 0.0831\n",
      "Epoch 29/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0834 - val_loss: 0.0830\n",
      "Epoch 30/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0832 - val_loss: 0.0830\n",
      "Epoch 31/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0832 - val_loss: 0.0826\n",
      "Epoch 32/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0832 - val_loss: 0.0827\n",
      "Epoch 33/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0831 - val_loss: 0.0826\n",
      "Epoch 34/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0832 - val_loss: 0.0833\n",
      "Epoch 35/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0831 - val_loss: 0.0829\n",
      "Epoch 36/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0832 - val_loss: 0.0826\n",
      "Epoch 37/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0831 - val_loss: 0.0827\n",
      "Epoch 38/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0831 - val_loss: 0.0826\n",
      "Epoch 39/100\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.0833 - val_loss: 0.0830\n",
      "Epoch 40/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0834 - val_loss: 0.0830\n",
      "Epoch 41/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0832 - val_loss: 0.0827\n",
      "Completed Training with Latent Space Dimension for Small NN: 30\n",
      "\n",
      "\n",
      "Start Training with Latent Space Dimension for Small NN: 40\n",
      "\n",
      "Epoch 1/100\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1068 - val_loss: 0.0886\n",
      "Epoch 2/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0896 - val_loss: 0.0882\n",
      "Epoch 3/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0891 - val_loss: 0.0876\n",
      "Epoch 4/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0880 - val_loss: 0.0852\n",
      "Epoch 5/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0854 - val_loss: 0.0849\n",
      "Epoch 6/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0851 - val_loss: 0.0844\n",
      "Epoch 7/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0848 - val_loss: 0.0840\n",
      "Epoch 8/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0846 - val_loss: 0.0840\n",
      "Epoch 9/100\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.0845 - val_loss: 0.0839\n",
      "Epoch 10/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0844 - val_loss: 0.0838\n",
      "Epoch 11/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0844 - val_loss: 0.0838\n",
      "Epoch 12/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0843 - val_loss: 0.0836\n",
      "Epoch 13/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 14/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0842 - val_loss: 0.0837\n",
      "Epoch 15/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0842 - val_loss: 0.0835\n",
      "Epoch 16/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0841 - val_loss: 0.0836\n",
      "Epoch 17/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0841 - val_loss: 0.0835\n",
      "Epoch 18/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0841 - val_loss: 0.0835\n",
      "Epoch 19/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0840 - val_loss: 0.0834\n",
      "Epoch 20/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0839 - val_loss: 0.0834\n",
      "Epoch 21/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0838 - val_loss: 0.0833\n",
      "Epoch 22/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0838 - val_loss: 0.0834\n",
      "Epoch 23/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0836 - val_loss: 0.0832\n",
      "Epoch 24/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0835 - val_loss: 0.0829\n",
      "Epoch 25/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0834 - val_loss: 0.0828\n",
      "Epoch 26/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0834 - val_loss: 0.0829\n",
      "Epoch 27/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0833 - val_loss: 0.0829\n",
      "Epoch 28/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0833 - val_loss: 0.0827\n",
      "Epoch 29/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0832 - val_loss: 0.0826\n",
      "Epoch 30/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0832 - val_loss: 0.0828\n",
      "Epoch 31/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0832 - val_loss: 0.0826\n",
      "Epoch 32/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0832 - val_loss: 0.0826\n",
      "Epoch 33/100\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0831 - val_loss: 0.0828\n",
      "Epoch 34/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0831 - val_loss: 0.0827\n",
      "Epoch 35/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0830 - val_loss: 0.0829\n",
      "Epoch 36/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0831 - val_loss: 0.0827\n",
      "Epoch 37/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0831 - val_loss: 0.0825\n",
      "Epoch 38/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0831 - val_loss: 0.0825\n",
      "Completed Training with Latent Space Dimension for Small NN: 40\n",
      "\n",
      "\n",
      "Start Training with Latent Space Dimension for Small NN: 50\n",
      "\n",
      "Epoch 1/100\n",
      "108/108 [==============================] - 2s 8ms/step - loss: 0.1056 - val_loss: 0.0888\n",
      "Epoch 2/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0896 - val_loss: 0.0880\n",
      "Epoch 3/100\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.0888 - val_loss: 0.0863\n",
      "Epoch 4/100\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.0858 - val_loss: 0.0843\n",
      "Epoch 5/100\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0851 - val_loss: 0.0841\n",
      "Epoch 6/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0848 - val_loss: 0.0839\n",
      "Epoch 7/100\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.0846 - val_loss: 0.0838\n",
      "Epoch 8/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0845 - val_loss: 0.0837\n",
      "Epoch 9/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0845 - val_loss: 0.0838\n",
      "Epoch 10/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0844 - val_loss: 0.0837\n",
      "Epoch 11/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0843 - val_loss: 0.0836\n",
      "Epoch 12/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 13/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0842 - val_loss: 0.0837\n",
      "Epoch 14/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 15/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0841 - val_loss: 0.0835\n",
      "Epoch 16/100\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.0841 - val_loss: 0.0836\n",
      "Epoch 17/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0840 - val_loss: 0.0835\n",
      "Epoch 18/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0840 - val_loss: 0.0835\n",
      "Epoch 19/100\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0840 - val_loss: 0.0834\n",
      "Epoch 20/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0839 - val_loss: 0.0834\n",
      "Epoch 21/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0839 - val_loss: 0.0834\n",
      "Epoch 22/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0838 - val_loss: 0.0833\n",
      "Epoch 23/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0837 - val_loss: 0.0831\n",
      "Epoch 24/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0836 - val_loss: 0.0830\n",
      "Epoch 25/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0835 - val_loss: 0.0829\n",
      "Epoch 26/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0835 - val_loss: 0.0830\n",
      "Epoch 27/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0833 - val_loss: 0.0828\n",
      "Epoch 28/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0833 - val_loss: 0.0827\n",
      "Epoch 29/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0833 - val_loss: 0.0830\n",
      "Epoch 30/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0833 - val_loss: 0.0831\n",
      "Completed Training with Latent Space Dimension for Small NN: 50\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tune_dim = [30,40,50]\n",
    "results = []\n",
    "for dim in tune_dim:\n",
    "    print('Start Training with Latent Space Dimension for Large NN: ' + str(dim) + '\\n')\n",
    "    results.append(train_large_nn(dim))\n",
    "    print('Completed Training with Latent Space Dimension for Large NN: ' + str(dim) + '\\n\\n')\n",
    "    \n",
    "for dim in tune_dim:\n",
    "    print('Start Training with Latent Space Dimension for Small NN: ' + str(dim) + '\\n')\n",
    "    results.append(train_small_nn(dim))\n",
    "    print('Completed Training with Latent Space Dimension for Small NN: ' + str(dim) + '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115ae695-94b1-4eed-9790-fa391a36f536",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  FutureWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  FutureWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  FutureWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  FutureWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  FutureWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "svd4 = TruncatedSVD(n_components=30, n_iter=20, random_state=42)\n",
    "all_teams_reduced30 = svd4.fit_transform(teamscaler.fit_transform(all_teams_df))\n",
    "svd5 = TruncatedSVD(n_components=40, n_iter=20, random_state=42)\n",
    "all_teams_reduced40 = svd5.fit_transform(teamscaler.fit_transform(all_teams_df))\n",
    "svd6 = TruncatedSVD(n_components=50, n_iter=20, random_state=42)\n",
    "all_teams_reduced50 = svd6.fit_transform(teamscaler.fit_transform(all_teams_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efde50c7-bc0d-405a-b16a-6ce4e9785f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Teams SVD Hyperparameter Tuning: \n",
      "MAE of 30 Components: 0.06695705574612534\n",
      "MAE of 40 Components: 0.062094372041886614\n",
      "MAE of 50 Components: 0.05822202128957278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  FutureWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "print('For Teams SVD Hyperparameter Tuning: ')\n",
    "\n",
    "d = teamscaler.fit_transform(all_teams_df).copy()\n",
    "d = pd.DataFrame(d)\n",
    "\n",
    "c = pd.DataFrame(svd4.inverse_transform(all_teams_reduced30))\n",
    "e = abs(c-d).mean().mean()\n",
    "print('MAE of 30 Components: ' + str(e))\n",
    "\n",
    "c = pd.DataFrame(svd5.inverse_transform(all_teams_reduced40))\n",
    "e = abs(c-d).mean().mean()\n",
    "print('MAE of 40 Components: ' + str(e))\n",
    "\n",
    "c = pd.DataFrame(svd6.inverse_transform(all_teams_reduced50))\n",
    "e = abs(c-d).mean().mean()\n",
    "print('MAE of 50 Components: ' + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9887c720-02c3-436c-bb19-4fadf94a3216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Teams Large NN Autoencoder Hyperparameter Tuning: \n",
      "MAE of Dimension 30: 0.08352683484554291\n",
      "MAE of Dimension 40: 0.08350678533315659\n",
      "MAE of Dimension 50: 0.08354625850915909\n",
      "\n",
      "For Teams Small NN Autoencoder Hyperparameter Tuning: \n",
      "MAE of Dimension 30: 0.08259359002113342\n",
      "MAE of Dimension 40: 0.0824931263923645\n",
      "MAE of Dimension 50: 0.08271608501672745\n"
     ]
    }
   ],
   "source": [
    "print('For Teams Large NN Autoencoder Hyperparameter Tuning: ')\n",
    "print('MAE of Dimension 30: ' + str(min(results[0].history['val_loss'])))\n",
    "print('MAE of Dimension 40: ' + str(min(results[1].history['val_loss'])))\n",
    "print('MAE of Dimension 50: ' + str(min(results[2].history['val_loss'])))\n",
    "\n",
    "print('\\nFor Teams Small NN Autoencoder Hyperparameter Tuning: ')\n",
    "print('MAE of Dimension 30: ' + str(min(results[3].history['val_loss'])))\n",
    "print('MAE of Dimension 40: ' + str(min(results[4].history['val_loss'])))\n",
    "print('MAE of Dimension 50: ' + str(min(results[5].history['val_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f991a7fe-6345-477b-b550-8435b48d0df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1073 - val_loss: 0.0886\n",
      "Epoch 2/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0896 - val_loss: 0.0880\n",
      "Epoch 3/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0890 - val_loss: 0.0873\n",
      "Epoch 4/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0865 - val_loss: 0.0845\n",
      "Epoch 5/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.0850 - val_loss: 0.0842\n",
      "Epoch 6/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0847 - val_loss: 0.0840\n",
      "Epoch 7/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0846 - val_loss: 0.0838\n",
      "Epoch 8/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0845 - val_loss: 0.0843\n",
      "Epoch 9/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0844 - val_loss: 0.0838\n",
      "Epoch 10/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0843 - val_loss: 0.0837\n",
      "Epoch 11/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0843 - val_loss: 0.0837\n",
      "Epoch 12/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0842 - val_loss: 0.0837\n",
      "Epoch 13/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 14/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0842 - val_loss: 0.0835\n",
      "Epoch 15/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0842 - val_loss: 0.0835\n",
      "Epoch 16/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0841 - val_loss: 0.0835\n",
      "Epoch 17/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0841 - val_loss: 0.0835\n",
      "Epoch 18/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0841 - val_loss: 0.0838\n",
      "Epoch 19/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0840 - val_loss: 0.0834\n",
      "Epoch 20/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0840 - val_loss: 0.0835\n",
      "Epoch 21/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0840 - val_loss: 0.0835\n",
      "Epoch 22/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0839 - val_loss: 0.0834\n",
      "Epoch 23/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0839 - val_loss: 0.0835\n",
      "Epoch 24/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0839 - val_loss: 0.0834\n",
      "Epoch 25/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0839 - val_loss: 0.0834\n",
      "Epoch 26/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0837 - val_loss: 0.0832\n",
      "Epoch 27/200\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0837 - val_loss: 0.0831\n",
      "Epoch 28/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0836 - val_loss: 0.0831\n",
      "Epoch 29/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0836 - val_loss: 0.0831\n",
      "Epoch 30/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0835 - val_loss: 0.0830\n",
      "Epoch 31/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0835 - val_loss: 0.0829\n",
      "Epoch 32/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0833 - val_loss: 0.0828\n",
      "Epoch 33/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0833 - val_loss: 0.0826\n",
      "Epoch 34/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.0832 - val_loss: 0.0826\n",
      "Epoch 35/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0833 - val_loss: 0.0828\n",
      "Epoch 36/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0831 - val_loss: 0.0825\n",
      "Epoch 37/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0832 - val_loss: 0.0824\n",
      "Epoch 38/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0830 - val_loss: 0.0825\n",
      "Epoch 39/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.0834 - val_loss: 0.0828\n",
      "Epoch 40/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0831 - val_loss: 0.0826\n",
      "Epoch 41/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0830 - val_loss: 0.0829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8ac60aa1d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_small_nn(emb_dim = 50, epochs=200, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2 (Local)",
   "language": "python",
   "name": "local-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
